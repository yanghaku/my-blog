{"meta":{"title":"YangBo","subtitle":"君子曰:学不可以已","description":"一个快废掉的咸鱼罢了","author":"杨博","url":"https://yanghaku.github.io","root":"/"},"pages":[{"title":"about the author of this blog","date":"2019-05-17T05:29:39.000Z","updated":"2019-05-20T16:04:29.000Z","comments":false,"path":"about/index.html","permalink":"https://yanghaku.github.io/about/index.html","excerpt":"","text":"github: yanghaku qq: 1961882079 school: neu"},{"title":"categories","date":"2019-05-20T16:01:56.000Z","updated":"2019-05-20T16:04:45.000Z","comments":false,"path":"categories/index.html","permalink":"https://yanghaku.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-05-20T16:05:36.000Z","updated":"2019-05-20T16:05:59.000Z","comments":false,"path":"tags/index.html","permalink":"https://yanghaku.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"C# 语言基础","slug":"cs语言基础","date":"2020-02-26T04:39:00.000Z","updated":"2020-02-28T12:23:52.542Z","comments":true,"path":"2020/02/26/cs语言基础/","link":"","permalink":"https://yanghaku.github.io/2020/02/26/cs%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/","excerpt":"程序结构Hello World!:","text":"程序结构Hello World!: 123456789101112using System;/** * this is an example code for c# */namespace ConsoleApp1 &#123; class Program &#123; public static void Main(string[] arg) &#123; // print hello world! Console.WriteLine(\"Hello World!\"); &#125; &#125;&#125; C#是一个面向对象的语言，并且吸收了java，c++等语言的某些优点。内部的Program类的写法非常像java，static void Main函数为程序的入口。static与java的一样，为静态函数的关键字。注释符也与java、c++的一样，两种：行内注释// 和多行注释 /** */ 然后就是命名空间的问题： namespace 与 using在c#中，每一个类应该都在一个命名空间里面。功能上与c++的namespace，java里的package一样，用于变量标识符的冲突，区别不同的属性等。在java中，每个packet，类都与文件系统的文件夹（包名与文件夹名字相同）、文件（类名要和文件名相同）相对应，整个可以发布成一个jar包供人使用。而c#不必要与文件相对应，一个文件里面可以有多个类，也可以有多个命名空间（也可以嵌套）。同一个命名空间下的类可以包装成一个程序集供用户调用。编译后的程序集可以是.exe 或者.dll,具体取决于是开发的应用程序还是开发的库。 调用的时候直接加.即可。example：12345678910111213141516171819202122232425262728293031323334using System;namespace ConsoleApp1 &#123; class Program &#123; public static void Main(string[] arg) &#123; myName1.C.F(); myName2.C.F(); myName1.myname2.C.F(); &#125; &#125; namespace myName1 &#123; class C &#123; public static void F() &#123; Console.WriteLine(\"myName1::C::f()\"); &#125; &#125; namespace myname2 &#123; class C &#123; public static void F() &#123; Console.WriteLine(\"myname1::myName2::C::F()\"); &#125; &#125; &#125; &#125; namespace myName2 &#123; class C &#123; public static void F() &#123; Console.WriteLine(\"myName2::C::F()\"); &#125; &#125; &#125;&#125;运行结果：123myName1::C::f()myName2::C::F()myname1::myName2::C::F() 从上面这个例子就可以学到命名空间的使用和命名空间的嵌套。 当调用其他namespace程序集的时候，每次都是namespace1.subnamespace1.subsub…..这个样子的肯定写起来也非常麻烦，所以就有了using关键字。(像java的import)using可以直接引入某个命名空间，然后使用这个命名空间里的所有类12using System;using Namespace1.SubNamespace;using也可以用来起别名：1using Syyys = System;using static 指令可以直接引入static变量比如要使用System.Math类的静态变量，可以每次写System.Math.PI,也可以使用using static System.Math引入Math类的静态变量，这样每次使用都可以直接用PI这个变量了：double xx=PI; 数据类型C#中，变量有三种类型：值类型（Value types），引用类型（Reference types），指针类型（Pointer types）。 值类型值类型变量是变量本身直接包含数据（存储在栈中），值类型每一个变量都有一个自己的数据副本，对一个变量执行操作不会影响其他变量（当然，ref与out的时候除外）。 值类型的还可以细分类： 简单类型：int,double,bool,char等内置类型 枚举类型：enum E{} 等用户自定义的类型 结构类型：struct S{} 等用户自定义的类型 可以为null的类型 简单类型（内置值类型）在C#中，内置类型的变量都是继承自System.ValueType类,相当于一种特殊的，不是引用类型变量的类，在分配的时候，会将变量的实例（值）复制。（但是继承后的Int32是结构类型，而不是类类型），这个可以详细看后面的struct结构类型。比如int类型其实就是System.Int32类型的别名，这两个是一个效果：123int p = 10;System.Int32 p = 10;// 两者等价 简单类型都可以使用const关键字来声明简单类型的常数，可以用文字来为简单类型提供值。其中分为四种类型：整数值类型、浮点数值类型、布尔值类型、char字符类型 整数值类型整数值类型有 8位整数：sbyte（System.SByte）(有符号)、byte（System.Byte）(无符号) 16位整数：short（System.Int16）(有符号)、ushort（System.UInt16）(无符号) 32位整数：int（System.Int32）(有符号)、uint（System.UInt32）(无符号) 64位整数：long（System.Int64）(有符号)、ulong（System.UInt64）(无符号)每种类型都有两个静态变量MinValue和MaxValue，提供这个类型的最大值和最小值 整数文本可以有三种表示：10进制（无前缀），16进制（0x/0X），2进制（0b/0B）(下划线可以作为数字的分隔符)example：123int decimalLiteral = 42;int hexLiteral = 0x2A;int binaryLiteral = 0b_0010_1010; 浮点数值类型 4个字节：float（System.Single） 8个字节：double（System.Double） 16个字节：decimal（System.Decimal）每个类型都有两个常量：MinValue、MaxValue值其中float和double还提供了三个常量：NAN（非数字）、NegativeInfinity（负无穷）、PositiveInfinity（正无穷）。decimal相比double，表示范围小，但是精度高（可以精确到28-29位）。 数值文本中，用后缀来区分三种表示： float：f/F double: d/D/不带后缀 decimal: m/M example：1234567float x1 = 1.111f;float x2 = 1.111F;double p1 = 3.14;double p2 = 3.14d;double p3 = 3.14D;decimal s1 = 456.333e13m;decimal s2 = 456.333M; 布尔类型bool类型关键字，是System.Boolean的别名，值为true或false 用文本赋值的时候，也是true和falseexample:12bool flag = true;System.Boolean b = false; 字符类型char类型关键字，是System.Char的别名，与其他语言的char不同的是，c#的char是双字节（16位）表示的是Unicode UTF-16字符。string类型就是char的序列（所以也是Unicode UTF-16编码）char的默认值是’\\0’,即 U+0000。 用文本指定char值的时候，可以是字符文本、Unicode转义字符(\\u)、十六进制文本(\\x)example：1234char ch = 'h';char ch = '\\u0068';char ch = '\\x0068';char ch = (char)104;这4种ch的声明是一样的。 简单值类型的四种就完事了，接下来就是介绍第二种值类型：枚举类型 枚举类型枚举类型是用一组整数数值的命名常量定义的值类型。用enum来定义比如：123enum Days&#123; Sun, Mon, tue, Wed, thu, Fri, Sat&#125;;默认情况下关联的数值都是int类型，从0开始，并且往后递增1。也可以显式指定：12345enum Port : ushort&#123; http = 80, https = 443, ftp = 20&#125;;枚举类型的抽象基类是System.Enum,提供多种方法获取有关枚举类型的值和信息。 第三种值类型就是struct{} 定义的结构类型了。 结构类型结构类型是值类型，定义的结构体实例化之后，值是存在栈中的。在c#中的结构与其他的不一样，结构只是一种简单的，与class相比功能少很多的类型。特点： 结构可以带方法、字段、索引、属性、运算符方法和事件 结构可定义构造函数，但是不能定义析构函数。而且不能定义无参构造函数（因为已经默认定义好了）。 结构不能继承，不能被继承，也就是结构不能成为其他结构或者类的基础结构。 结构可以实现接口 结构成员不能为abstract、virtual、protected new 操作符创建结构对象时，会调用对应的构造函数，但是在new之前已经被实例化（分配空间了）。 不使用new操作符时，只有所有字段都被初始化后，才能使用这个结构对象。 内置类型int，double，bool，char都是属于结构类型（所以内置简单类型都是值类型）。所以说，struct类型是所有值类型的基础。struct类型是不可以继承的，其父类 System.ValueType 只是内置简单类型的隐式基类（而不是显式继承）。ValueType是一个抽象类，可以用来传参的时候，将类型限定在ValueType的子类（值类型）隐式继承是不指明继承的父类的时候，自动继承的类。比如自定义的class隐式继承Object，自定义的struct和内置简单类型int等struct都是隐式继承ValueType。 具体可以看: c#中的隐式继承所以，struct虽然不能继承和被继承，但是所有自定义的struct都有一个父类ValueType。 example:123456789101112131415161718struct Point&#123; // struct 中不能为属性设置初始值，比如 double x=1d; (class才可以) public double X &#123; set; get; &#125; public double Y &#123; set; get; &#125; public Point(double x,double y) &#123; X = x; Y = y; &#125;&#125;// 结构虽然不能继承，但是可以作为其他结构的一个属性struct Line &#123; public Point P1 &#123; get; set; &#125; public Point P2 &#123; get; set; &#125; public Line(Point p1,Point p2) &#123; P1 = p1; P2 = p2; &#125;&#125;像Point这种数据特别小的类型，声明成struct，实例保存在栈中而不使用堆，可以提高效率。 可为空的值类型在默认情况下，C#中所有引用类型可以赋值为null，意味着该类型没有任何的值。但是值类型没有null这个值域，所以说int x=null这种语句就会编译报错。C#提供了一种特殊的数据类型，可以为值类型做扩展，让其在原有值的域的基础上外加一个null的值，这样值类型也可以用null来赋值表示其意义了。 实现的这个类是一个泛型struct：Nullable 123public struct Nullable&lt;T&gt; where T : struct// T 表示的是任意类型// where T ： struct 表示T的类型只能是struct的值类型 例如其中一个具体的Nullable 类，这就使int值域从原先的[$-2^{31}$,$2^{31}$]之外，增加了null。可以直接Nullable&lt;int&gt; x = null;Nullable重载了T的运算符，可以像T一样使用它。Nullable里面有两个属性： 布尔类型的HasValue，也就是保存着这个实例的值是不是null T 类型的Value，保存着T的值。 当HasValue为true时，Value就是这个实例的值，可以直接访问获取或修改；当HasValue为false时，这个实例的值就是null，Value不可访问，否则就会出现异常而终止。 Nullable声明的时候，可以直接简写为 T? 类型，也就是在值类型之后加一个?就可以表示这个值类型增加了null值域。example: 1234567891011121314151617181920212223242526272829303132333435using System;namespace ConsoleApp1 &#123; class Program &#123;//cc public static void Main(string[] arg) &#123; // 简单内置值类型的可为空 int? x = 10; int? y = null; if (x.HasValue) Console.WriteLine(\"x = \" + x); else Console.WriteLine(\"x = null\"); if (y.HasValue) Console.WriteLine(\"y = \" + y); else Console.WriteLine(\"y = null\"); int i1;//默认值为0 int? i2;//默认值为 null // 自定义的值类型的可为空 Point? p = null; Point? p1 = new Point(3d, 4d); Console.WriteLine(p1.Value.X); Console.WriteLine(p1.Value.Y); // 可为空的值类型的数组 int?[] list = new int?[10]; &#125; &#125; struct Point&#123; public double X &#123; set; get; &#125; public double Y &#123; set; get; &#125; public Point(double x,double y) &#123; X = x; Y = y; &#125; &#125;&#125; null 合并运算符: ?? 需要获取可为空的值的时候，可能需要分配指定的值来代替null，Nullable.GetValueOrDefault(T)这个方法就可以实现这个目的。参数T是传入的默认值。为了简便，两个问号操作符也可以达到这个目的(也作为一种简写)：example：12345int? x = 10;int? y = null;int p1 = x ?? 20; //等价于 x.GetValueOrDefault(20);int p2 = y ?? 20; //等价于 y.GetValueOrDefault(20);// p1=10,p2=20; 值类型总结总之，值类型的继承链为： 1234567891011|-- class Object（所有的父类）| || | --(显)-- class ValueType （所有值类型的父类）| | | --(显)-- class Enum | | | | --(隐)-- enum &#123;&#125; 自定义枚举值类型| | || | | --(隐)-- struct Int32等 （int，double，char 等内置值类型）| | || | | --(隐)-- struct Nullable&lt;T&gt; 实例是为可空值类型| | || | | --(隐)-- struct &#123;&#125;（自定义结构体值类型） （最终的实例都是struct，struct都是从上面的隐性继承）。 引用类型引用类型与值类型不同，变量存储的是引用的值的地址，对应的引用的值存在于堆中由CLR进行管理。多个变量可以引用同一个值，所以其中一个变量改变值的时候可能会改变另一个变量引用的对象。引用类型中变量赋值的时候，只是复制变量里的地址，也是引用的数据不会复制，复制后的变量与原先的变量指向同一块数据。 C#中，引用类型分为四类： 类类型：类类型有三种，其中两种为内置的类型（object和string） 所有的类型的基类： object(System.Object) Unicode字符串：string(System.String) 自定义类: 格式为 class C {...} 用户自定义的类类型 接口类型：格式为 interface I {...} 的用户自定义接口类型 数组类型：n维数组类型,如 int[],int[][],int[][][]…. 委托类型：格式为 delegate type D(...) 的用户自定义类型 数据类型转换隐式与显式类型转换隐式类型转换是C#默认的安全方式的转换，不会导致数据丢失。比如从小的整数转化为大的整数，从派生类转化为基类。例如：12int x = 10;long y = x;//隐式转换 大类型一般不能转化为小类型，比如long转化为int的时候就可能会丢失数据，强制类型的转换可能会导致溢出等问题。强制转换可以用(type)var ，也可以用System.Convert类的静态函数：example：1234double d = 1.34455555555;int x = (int)d;int y = System.Convert.ToInt32(d);//两者效果一样Console.WriteLine(\"x = &#123;0&#125;, y = &#123;1&#125;\",x,y); 装箱与拆箱装箱操作是把值类型转换为引用类型拆箱操作是把引用类型转化为值类型利用装箱和拆箱功能，允许值类型的任何值都与object类的值相互转化，让引用类型和值类型连接起来。 装箱会在堆上分配内存，将值类型的值复制到堆里，生成的引用变量指向这个产生的副本。复制之后就与原先装箱的值变量没有关系了，所以说不会影响到原先的值类型的值。example：123int val = 100;object obj1 = val;//隐式装箱，变为引用类型object obj2 = (object)val; //显式装箱拆箱是将装箱之后的引用变量的值（在堆里），复制到给定的值变量中，也是拷贝一个副本。注：（只有装箱后的引用变量才能拆箱！！）。123int val = 100;object obj = val;// 隐式装箱int copy = (int)obj;// 显式拆箱（不可隐式拆箱）拆箱和装箱都是对值的副本的拷贝，操作拷贝后的副本对原先的值不会造成影响。 可为空的值类型的装箱：如果HasValue为False，那就会返回null的引用；否则就跟正常装箱一样，将Value复制到堆里，然后引用变量指向这个复制的位置。拆箱的时候，可以将原先的值类型拆成可为空的值类型。可以看官网上的example： 12345678910111213int a = 41;object aBoxed = a;int? aNullable = (int?)aBoxed;Console.WriteLine($\"Value of aNullable: &#123;aNullable&#125;\");object aNullableBoxed = aNullable;if (aNullableBoxed is int valueOfA)&#123; Console.WriteLine($\"aNullableBoxed is boxed int: &#123;valueOfA&#125;\");&#125;// Output:// Value of aNullable: 41// aNullableBoxed is boxed int: 41 变量与常量一个变量只不过是供程序操作的存储区的名字，在C#中，每个变量都有一个特定的类型，类型决定着变量的内存大小和布局。C#中的变量定义与初始化与C++、java的一样，左值和右值的区分也相同。 其中var关键字可以让编译器自动识别类型（类似于c++的auto关键字），需要定义的时候就初始化，而且类型是不可改变的。example1var x = \"123456\"; //x 类型为string C#常量可以使用字面常量（内置的值类型,具体见上面的值类型介绍），也可以用const关键词来定义一个常量。example：12const int NUM = 30;const string str = \"stringstring\"; 运算符C#中的运算符与c++的类似，算术运算符、关系运算符、逻辑运算符、位运算符，赋值运算符都一样，只不过多了一些特殊的运算符： 类型测试is运算符：is ， 如E is T，测试E是否与给定类型T相兼容有匹配的测试：E is T v,如果E is T的表达式是true，那么就将E转换的结果分配给变量v。 as运算符：as运算符将结果强制转化为给定的引用，如果不能转换就返回null，永远不会造成异常。如obj = E as T ()强制转换运算符：用括号来进行显式强制转换，如果转换失败就会引发异常。如int x = (int)d; typeof()运算符：用于获取某个类型的System.Type实例。运行的时候可以用obj.GetType()方法来获取实例的Type。 ! (null包容)运算符：（skip） =&gt; 运算符：有两种形式：作为lambda运算符、作为成员名称的分隔符和表达式主体定义 的成员实现（这里只说第二种，lambda往后会再介绍）。表达式主体定义：member =&gt; expression其中expression是有效表达式，返回类型必须可隐式转化为成员的返回类型example： 1public override string ToString() =&gt; $\"&#123;fname&#125; &#123;lname&#125;\".Trim(); 这个是以下代码的简写： 123public override string ToString()&#123; return $\"&#123;fname&#125; &#123;lname&#125;\".Trim();&#125; 语句声明语句： var x = 10; 表达式语句：(x+1)/10; 选择语句： if(){} if(){}else{} if(){}else if(){}else{} switch(){} 三目运算符： exp1 ? exp2 : exp3; 迭代语句： while(){} do{}while(); for(;;;){} foreach语句,如： foreach (var s in list){} 跳转语句： break continue default goto return yield 异常处理： throw try{}catch(){}finally{} 空语句： 只含分号 ; 参考链接 C#菜鸟教程 C#文档 介绍面向 Java 开发人员的 C# 编程","categories":[{"name":".NET学习","slug":"NET学习","permalink":"https://yanghaku.github.io/categories/NET%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":".NET","slug":"NET","permalink":"https://yanghaku.github.io/tags/NET/"}]},{"title":".NET Framework 与 CLR 概述","slug":"NET Framework概述","date":"2020-02-25T09:39:00.000Z","updated":"2020-02-26T10:28:18.182Z","comments":true,"path":"2020/02/25/NET Framework概述/","link":"","permalink":"https://yanghaku.github.io/2020/02/25/NET%20Framework%E6%A6%82%E8%BF%B0/","excerpt":".NET Framework.NET Framework 是 .NET 框架的一种实现（在windows平台上），用于代码编译和执行的集成托管环境。它包括两个部分：CLR（Common Language Runtime，公共语言运行时）和 FCL（Framework Class Library,.NET Framework Library类库）。公共语言运行时是.NET Framework 的基础。CLR可以看做一个执行时管理代码的代理，能够提供内存管理、线程管理等核心服务，并且还能强制实施严格的类型安全等来保证代码的准确性。以运行时为目标的代码称为托管代码，不以运行时为目标的代码称为非托管代码。类库是一个综合性的面向对象的可重用类型集合，可以用来开发命令行、GUI、基于ASP.NET的web窗体等应用。环境的结构图：","text":".NET Framework.NET Framework 是 .NET 框架的一种实现（在windows平台上），用于代码编译和执行的集成托管环境。它包括两个部分：CLR（Common Language Runtime，公共语言运行时）和 FCL（Framework Class Library,.NET Framework Library类库）。公共语言运行时是.NET Framework 的基础。CLR可以看做一个执行时管理代码的代理，能够提供内存管理、线程管理等核心服务，并且还能强制实施严格的类型安全等来保证代码的准确性。以运行时为目标的代码称为托管代码，不以运行时为目标的代码称为非托管代码。类库是一个综合性的面向对象的可重用类型集合，可以用来开发命令行、GUI、基于ASP.NET的web窗体等应用。环境的结构图：这样的框架，使得不同的语言可以同时在一个项目里，支持多平台，而且提供了更安全的执行环境。 Common Language RuntimeCILCIL(Common Intermediate Language，也叫IL，公共中间语言)是.NET 兼容语言的源码编译成的中间语言，可以在任意的.NET运行时上运行，并且有安全的内存和类型检查。 CLRCLR是 .NET framework 的核心，提供管理内存、线程执行、代码执行、代码安全验证、编译以及其他的系统服务。类似于JVM虚拟机，为IL提供运行环境。对于CLR来说，只看IL即可，而不用管IL由哪种语言编译而来的。CLR主要有JIT（实时编译器），GC（垃圾收集器）和BCL（基类库）等部分组成。JIT：just in time，即时编译器，运行的时候将IL编译成二进制的本地语言GC：垃圾收集器，实现内存管理回收垃圾等BCL（base class Library）基础类库，一个公共的编程框架，实现了网络操作，I/O操作，文本操作，数据库操作，XML操作等最基础的类，为所有的框架提供基础支持。 CLI与CTS、CLS由于过去语言和平台的不同，编译语言的内置类型各不相同，为了统一协作，必须有一组标准，这个标准就是CLI（Common Language Infrastructure，公共语言基础结构）。核心是CTS（Common Type System，通用类型系统）和CLS（Common Language Specification，公共语言规范）。CTS定义了在托管代码中一定会使用的类型特征，比如定义了一组内置类型以及每种类型的固有的独有的特征。CLS详细说明了一个.NET兼容编程语言的规则、属性、行为，其主题包括数据类型、类结构、参数传递等。遵循这个标准的语言，能够编译成IL，并可以在.NET框架里面就可以实现相互调用。（CLI是一个国际标准，.NET只是CLI的一个具体实现） 托管代码与非托管代码托管代码（managed code）与非托管代码（unmanaged code）：托管代码是IL，由CLR来运行管理，可以在不同的平台之间兼容，享受CLR提供的垃圾回收等服务。非托管代码是直接编译成的机器码，依赖于平台和语言，而且要自己实现垃圾回收等操作。在.NET里的JIT和java的不一样，在.NET程序被载入内存后，如果某段IL是第一次被运行，JIT就会编译这段IL代码，全部编译成本地代码再执行（所以第一次启动很慢）。微软还附带了可以事先将IL编译成本地代码保存起来的工具，这样执行的效率也就跟静态编译的一样了。（而java是解释器，两者效率根本不同）。JIT的优化可以针对本地的CPU，在编译的时候进行优化。而非托管的代码提前编译的时候为了兼容通常使用通用的指令集。所以JIT充分利用CPU的附加指令，效率的提升是很可观的。 .NET Framework Class Library （FCL）.NET Framework Library是一个与公共语言运行时密切结合的可重用的类型集合。一个面向对象的类库，大部分实现都引用了BCL的东西，是一个大粒度的类库，针对不同的应用程序设计的框架。可以通过GCL用.NET framework开发以下应用： Console控制台应用 Windows GUI 窗体应用 Windows Presentation（WPF）应用 ASP.NET 应用 windows服务 etc…. 参考链接 .NET Framework 概述：https://docs.microsoft.com/zh-cn/dotnet/framework/get-started/overview","categories":[{"name":".NET学习","slug":"NET学习","permalink":"https://yanghaku.github.io/categories/NET%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":".NET","slug":"NET","permalink":"https://yanghaku.github.io/tags/NET/"},{"name":".NET Framework","slug":"NET-Framework","permalink":"https://yanghaku.github.io/tags/NET-Framework/"}]},{"title":"SDN中简单模拟DDOS检测与防御","slug":"sflowmininet简单模拟ddos","date":"2020-02-21T03:20:00.000Z","updated":"2020-02-21T12:40:42.446Z","comments":true,"path":"2020/02/21/sflowmininet简单模拟ddos/","link":"","permalink":"https://yanghaku.github.io/2020/02/21/sflowmininet%E7%AE%80%E5%8D%95%E6%A8%A1%E6%8B%9Fddos/","excerpt":"使用自定义python脚本，自动利用mininet构建虚拟网络并且设置sflow-rt流量监控，ryu为控制器。 架构：","text":"使用自定义python脚本，自动利用mininet构建虚拟网络并且设置sflow-rt流量监控，ryu为控制器。 架构： 从上图中可以看到，mininet基于OVS构建出网络之后，由ryu通过南向协议控制，交换机设置sFlow agent之后，采集的flow信息传给sflow-rt收集，然后用户通过REST API实现与ryu和sflow-rt进行通信，从sflow-rt获取流量信息或者向ryu请求添加/删除某些流表。 REST API 介绍REST是Representational State Transfer（表现层状态转移）的缩写，它是由罗伊·菲尔丁（Roy Fielding）提出的，是用来描述创建HTTP API的标准方法的，他发现这四种常用的行为（查看（view），创建（create），编辑（edit）和删除（delete））都可以直接映射到HTTP 中已实现的GET,POST,PUT和DELETE方法。REST API也就是通过HTTP协议实现规定了这四大行为，实现“表现层的状态转化”。每一个URL对应着一个资源，客户与服务端之间传递某种资源的表现层。返回的数据的形式可以是html，json，xml等。 ryu的app实现了某些REST API，默认的端口是8080，sFlow-rt实现的的默认端口是8008比如说ryu的ofctl_rest.py 里面实现的REST API，在源码里都有对应介绍（详见最下面的附录）。sflow-rt的API（需要启动sflow-rt后查看） http://(sflow_rt_IP):8008/api/index.html 访问这些api就通过http请求即可比如用python的request库或者命令行curl 例：curl查看sflow agent 1234567891011121314151617181920212223yb@sdn-server:~$ curl http:/127.0.0.1:8008/agents/json&#123;\"127.0.0.1\": &#123; \"sFlowDatagramsLost\": 0, \"sFlowDatagramSource\": [\"127.0.0.1\"], \"firstSeen\": 1137756, \"sFlowFlowDuplicateSamples\": 0, \"sFlowDatagramsReceived\": 451732, \"sFlowCounterDatasources\": 9, \"sFlowFlowOutOfOrderSamples\": 0, \"sFlowFlowSamples\": 4506494, \"sFlowDatagramsOutOfOrder\": 2, \"uptime\": 973000, \"sFlowCounterDuplicateSamples\": 0, \"lastSeen\": 156756, \"sFlowDatagramsDuplicates\": 0, \"sFlowFlowDrops\": 0, \"sFlowFlowLostSamples\": 0, \"sFlowCounterSamples\": 867, \"sFlowCounterLostSamples\": 0, \"sFlowFlowDatasources\": 7, \"sFlowCounterOutOfOrderSamples\": 0&#125;&#125;yb@sdn-server:~$ 工具的默认端口： 控制器：6653，6633 控制器REST API：8080 sflow agent：6343 sflow-rt REST API：8008 下面就是具体操作了： 启动sflow-rt123456789101112yb@sdn-server:~$ ./sflow-rt/start.sh2020-02-21T03:14:32Z INFO: Starting sFlow-RT 3.0-14482020-02-21T03:14:36Z INFO: Version check, 3.0-1469 available2020-02-21T03:14:36Z INFO: Listening, sFlow port 63432020-02-21T03:14:36Z INFO: Listening, HTTP port 80082020-02-21T03:14:37Z INFO: app/mininet-dashboard/scripts/metrics.js started2020-02-21T03:14:37Z INFO: app/dashboard-example/scripts/metrics.js started2020-02-21T03:14:37Z INFO: app/flow-graph/scripts/graph.js started2020-02-21T03:14:37Z INFO: app/world-map/scripts/countries.js started2020-02-21T03:14:37Z INFO: app/flow-trend/scripts/top.js started2020-02-21T03:14:37Z INFO: app/ix-metrics/scripts/metrics.js started... 此时sflow监听开启 启动ryu在这里需要用到ryu的两个app:simple_switch_13.py 实现交换机(OpenFlow1.3协议)的转发功能ofctl_rest.py 用于通过REST API进行添加/删除流表，实现阻止DDOS的流量两个都在ryu安装目录的app里面 启动：123456789101112yb@sdn-server:~$ ryu-manager ryu/app/simple_switch_13.py ryu/app/ofctl_rest.p yloading app ryu/app/simple_switch_13.pyloading app ryu/app/ofctl_rest.pyloading app ryu.controller.ofp_handlerinstantiating app None of DPSetcreating context dpsetcreating context wsgiinstantiating app ryu/app/simple_switch_13.py of SimpleSwitch13instantiating app ryu.controller.ofp_handler of OFPHandlerinstantiating app ryu/app/ofctl_rest.py of RestStatsApi(10379) wsgi starting up on http://0.0.0.0:8080... 启动mininet构建虚拟网络这个是最关键的，使用python脚本，实现自定义的拓扑，并且将每个交换机都设置好控制器和sflow代理。 如果不需要自定义的话，简单一个命令就可以搞定， —custom来设定的sflow-rt/extras里面的sflow.py就是可以自动将mininet里的交换机设置代理。12sudo mn --controller=remote,ip=127.0.0.1,port=6633 --customsflow-rt/extras/sflow.py --switch ovs,protocols=OpenFlow13 但是，为了可以实现复杂的网络拓扑，还有其他特性的设置，编写自定义的脚本还是非常非常重要的。 下面就是实现的一个自定义脚本： 首先是实现一个自定义的拓扑类（继承mininet.topo.Topo）,构造函数的参数是交换机的个数和主机个数，建边的函数就决定了拓扑的复杂性（这里只是简单测试，所以写的建边函数只是线性连接的）。 customTopology.py(具体看注释):1234567891011121314151617181920212223242526272829303132333435363738#!/usr/bin/env python# coding:utf-8from mininet.topo import Topo# 自定义拓扑类class CustomTopology(Topo): # 构造函数,s_num为交换机个数,h_num为主机个数 def __init__(self, switch_num, host_num): print '*** Class CustomTopology init' self.switch_list = [] # 交换机列表初始化 self.host_list = [] # 主机列表初始化 Topo.__init__(self) # 父类构造函数 self.create_nodes(switch_num, host_num) # 创建节点 self.create_links() # 创建链路 print '*** Class CustomTopology init Success' # 创建节点的函数 def create_nodes(self, switch_num, host_num): print '*** Add switches and hosts to Topology' for i in xrange(1, switch_num + 1): self.switch_list.append(self.addSwitch(\"s%d\" % i)) for i in xrange(1, host_num + 1): self.host_list.append(self.addHost('h%d' % i)) # 创建链路的函数, 建边函数决定了自定义拓扑的复杂度 def create_links(self): print '*** Add links to Topology' self.addLink(self.switch_list[0],self.switch_list[1]) for i in xrange(len(self.host_list)): if i &lt; 2: self.addLink(self.switch_list[0], self.host_list[i]) else: self.addLink(self.switch_list[1], self.host_list[i]) 然后就是创建网络的脚本了，需要import上面的customTopology.py具体顺序是：创建拓扑 -&gt; 根据拓扑创建网络 -&gt; 将交换机openflow协议设置成1.3版本 -&gt; 设置sflow代理，将所有交换机加入代理 -&gt; 将mininet的拓扑通过REST API发送给sflow-rt -&gt; 创建完成，打开mininet的CLI。 具体可以看代码createNet.py: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123#!/usr/bin/env python# coding:utf-8\"\"\"Mininet自定义脚本通过Mininet的API实现构建自定义网络，并设置sflow代理\"\"\"from mininet.net import Mininetfrom mininet.node import RemoteControllerfrom mininet.cli import CLIfrom mininet.link import TCLinkfrom mininet.util import quietRun, customClassimport osimport reimport requests # 导入request，通过REST API 与 sflow-rt 通信from customTopology import CustomTopology # 导入自定义的拓扑类# 设置交换机的OpenFlow协议版本def configOpenFlow(net, protocol): print '*** set ovs protocols =' + protocol cmd = 'ovs-vsctl set bridge %s protocols=' + protocol for s in net.switches: quietRun(cmd % s)# 设置sflow agentdef configSFlow(net, agent_ifname, collector, sampling, polling): print '*** config SFlow agent' cmd = 'ovs-vsctl -- --id=@sflow create sflow agent=%s target=%s sampling=%d polling=%d --' % \\ (agent_ifname, collector, sampling, polling) for s in net.switches: cmd += ' -- set bridge %s sflow=@sflow' % s quietRun(cmd)# 向sFlow-rt 发送当前拓扑def sendTopology(net, agent_ip, collector): print \"*** Sending topology\" nodes = &#123;&#125; links = &#123;&#125; for s in net.switches: nodes[s.name] = &#123;'agent': agent_ip, 'ports': &#123;&#125;&#125; path = '/sys/devices/virtual/net/' # 虚拟网络存储的位置 pattern = re.compile('(^.+)-(.+)') # 编译正则表达式，用于匹配所有 s1-eth1 这种设备 for child in os.listdir(path): # 遍历这个文件夹， 获取每个交换机的端口 parts = pattern.match(child) # 如果存在匹配并且交换机在node列表里，就加入配置 # 比如s1-eth1, parts.group(0)='s1-eth1' , parts.group(1)='s1', parts.group(2)='eth1' if parts is not None and parts.group(1) in nodes: # 获取端口的id ifindex = open(path + child + '/ifindex').read().strip('\\n') nodes[parts.group(1)]['ports'][child] = &#123;'ifindex': ifindex&#125; # 统计交换机两两之间是不是有连接link length = len(net.switches) for i in xrange(length): for j in xrange(i + 1, length): s1 = net.switches[i] s2 = net.switches[j] intfs = s1.connectionsTo(s2) # 两个交换机直接的连接 for intf in intfs: link = '%s-%s' % (s1.name, s2.name) links[link] = &#123; 'node1': s1.name, 'node2': s2.name, 'port1': intf[0].name, # 两个端口，一个属于s1，一个属于s2 'port2': intf[1].name &#125; # 向sFlow-rt 发送拓扑信息， sFlow-rt 端口默认8008 requests.put('http://%s:8008/topology/json' % collector, json=&#123;'nodes': nodes, 'links': links&#125;)# 创建网络的主函数, 参数分别是:控制器的ip, sFlow收集器(sFlow-rt)的ip, sFlow agent的网卡, Sflow agent的ipdef createNet(controller_ip, sFlow_collector, sFlow_agent_ifname, sFlow_agent_ip): # 初始化拓扑 topology = CustomTopology(2, 4) # Rate limit links to 10Mbps link = customClass(&#123;'tc': TCLink&#125;, 'tc,bw=10') # 根据初始化网络 net = Mininet(topo=topology, link=link, controller=None) # 增加控制器，控制器端口默认都是6633和6653 net.addController('ryu-controller', controller=RemoteController, ip=controller_ip, port=6633) # 启动网络 net.start() # 设置交换机的OpenFlow版本 configOpenFlow(net, 'OpenFlow13') # 设置sFlow agent configSFlow(net, sFlow_agent_ifname, sFlow_collector, 10, 10) # 向sFlow-rt 发送当前拓扑 sendTopology(net, sFlow_agent_ip, sFlow_collector) # 互相ping测试连通 net.pingAll() # 测试带宽 print \"*** Testing bandwidth between h1 and h4\" h1, h4 = net.get('h1', 'h4') net.iperf((h1, h4)) # 开启命令行 CLI(net) # 最后关闭网络 net.stop()if __name__ == '__main__': if os.getuid() != 0: print 'You are not root!!' else: # 预先定义的变量 controller_ip = '127.0.0.1' sFlow_collector = '127.0.0.1' sFlow_agent_ifname = 'lo' # 因为虚拟网络和收集器是在同一个主机，所以直接用环回测试网卡做agent即可 sFlow_agent_ip = '127.0.0.1' createNet(controller_ip, sFlow_collector, sFlow_agent_ifname, sFlow_agent_ip) 然后执行12chmod +x *.pysudo ./createNet.py 输出：12345678910111213141516171819yb@sdn-server:~/code$ sudo ./createNet.py*** Class CustomTopology init*** Add switches and hosts to Topology*** Add links to Topology*** Class CustomTopology init Success*** set ovs protocols =OpenFlow13*** config SFlow agent*** Sending topology*** Ping: testing ping reachabilityh1 -&gt; h2 h3 h4h2 -&gt; h1 h3 h4h3 -&gt; h1 h2 h4h4 -&gt; h1 h2 h3*** Results: 0% dropped (12/12 received)*** Testing bandwidth between h1 and h4*** Iperf: testing TCP bandwidth between h1 and h4*** Results: ['9.34 Mbits/sec', '10.0 Mbits/sec']mininet&gt; ... 脚本产生了一个4个host，2个switch的网络，s1连接着h1,h2,s2连接着h3,h4，s1和s2连接。 这个时候，就可以用浏览器打开sflow-rt的ip:8008, 点开任意的app可以看到对应监控的信息了,比如点开dashboard-example： 流量检测与处理脚本接下来就是通过sflow-rt获取流量数据进行处理判断了。流程是：在sflow-rt 定义一个流，然后注册这个流的阈值，这个流超过阈值的时候sflow-rt就会生成对应的事件，然后脚本一直等待得到这个事件，得到后进行处理即可。 假设模拟的是UDP的泛洪攻击（源端口不变）的检测与防御，那么就向sflow-rt 定义监控 目的ip和源udp端口两个特征。如果超过了这个值，那么就向ryu控制器发送信息（也是通过REST API），增加一个流表项：将这个流的处理动作变成drop，就实现了一次防御。 具体可以看代码和注释 ddosDection.py： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106#!/usr/bin/env python# coding:utf-8\"\"\"构建网络后, 通过REST API从sFlow-rt获取flow信息, 发现ddos攻击的时候, 通过REST API给控制器信息修改流表，实现防御测试udp\"\"\"import timeimport requestsimport json# 处理事件的函数def handle(controller_ip, event): ryu = 'http://' + controller_ip + ':8080/' # ryu的默认端口是8080 flowKey = event['flowKey'] dest_ip, source_udp = flowKey.split(',') msg = &#123; # 定义向控制器发送的信息，添加新的流表项 \"dpid\": 1, # Datapath ID # 没有action，默认就是丢掉 'priority': 4000, # 优先级调到最高 \"hard_timeout\": 120, # 设置硬生存时间，使当前阻塞只持续两分钟 \"match\": &#123; # 流表项的匹配域 \"dl_type\": 0x800, # 以太网头的类型0x80，也就是ip协议 \"nw_dst\": dest_ip + '/32', # 目的ip \"nw_proto\": 17, # ip 头的协议类型17， 也就是udp \"tp_src\": source_udp # udp的源端口 &#125; &#125; r = requests.post(ryu + 'stats/flowentry/add', data=json.dumps(msg)) if r.status_code == 200: print 'handle event: blocking the flowKey=%s\\n' % flowKey else: print 'handle event %s fail\\n' % flowKey# 运行的主函数def run(controller_ip, collector_ip): rt = 'http://' + collector_ip + ':8008' # sFlow-rt的默认端口是8008 # 定义一个流的信息, keys为记录的特征，现在设定是 ip目的地址，udp源端口 # value 设置的是统计单位为 帧 flow = &#123;'keys': 'ipdestination,udpsourceport', 'value': 'frames'&#125; # 设置流的名字是 udp_test_flow flow_name = 'udp_test_flow' # 使用REST API 发送给sFlow-rt status_code = requests.put('%s/flow/%s/json' % (rt, flow_name), data=json.dumps(flow)).status_code if status_code != 204: print 'PUT flow ERROR! status_code is ' + str(status_code) # 定义一个阈值信息作为度量值，如果超过了这个阈值就会生成事件发送过来 # metric 为定义的流名字, value为阈值, byFlow是以流为统计基础 threshold = &#123;'metric': flow_name, 'value': 100, 'byFlow': True, 'timeout': 2&#125; # 设置这个阈值事件的名字为 udp_test threshold_name = 'udp_test' # 使用REST API 发送给sFlow-rt status_code = requests.put('%s/threshold/%s/json' % (rt, threshold_name), data=json.dumps(threshold)).status_code if status_code != 204: print 'PUT threshold ERROR! status_code is ' + str(status_code) # 定义这个阈值之后，超过了就会生成一个事件，所以一直循环监控这个事件就可以了 # 事件的url, get参数里指明之前定义的阈值名字， 最大的返回事件个数等 event_url = '%s/events/json?thresholdID=%s&amp;maxEvents=10&amp;timeout=60' % (rt, threshold_name) # eventID 指明的是下一个接收的event 为 这个eventID 之后的，所以第一次的时候为 -1 eventID = -1 print 'listening event %s start' % threshold_name while True: r = requests.get(event_url + '&amp;eventID=' + str(eventID)) if r.status_code != 200: print 'GET events Error! HTTP response code is ' + str(r.status_code) print r.text break events = r.json() if len(events) == 0: continue # events 为json解析后的一个event的list，序号越小的eventID越大 eventID = events[0][\"eventID\"] events.reverse() for e in events: print '---------------------' print 'time: ' + time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(e['timestamp'] / 1000)) # 毫秒级时间戳除以1000变成秒级 print 'event: id=%d, thresholdID=%s, metric=%s' % (e['eventID'], e['thresholdID'], e['metric']) print 'threshold = %d , value = %d' % (e['threshold'], e['value']) ip, udp = e['flowKey'].split(',') print 'flowKey: ipdestination = %s, udpsourceport = %s' % (ip, udp) print # 处理这个事件 handle(controller_ip, e) time.sleep(1) # 等待1sif __name__ == '__main__': run('127.0.0.1', '127.0.0.1') 先在刚才mininet的CLI运行：(hping3工具是可以模拟ddos工具，使用前需要先sudo apt install hping3) 1h1 hping3 --flood --udp -k -s 53 h3 —flood 是尽可能快得发送， —udp是构造udp模式， -k 保持源端口 -s 53 基础源端口设置53 然后再运行检测防御的脚本python ddosDection.py可以看到, 开始的时候出现流量暴增，当运行了脚本之后，流量下降一大半: 脚本的输出： 总结总之，实现了脚本自动构建网络，设置sflow代理等。 在这个架构上，控制器ryu，sFlow收集器sflow-rt，mininet构建的虚拟网络都可以在不同的主机上，设置好ip地址即可。 不足/需要完善的地方: sflow-rt 和 mininet搭建的网络还不能分散在不同的主机上（因为代理用的lo环回测试网卡） sflow-rt的REST API和ryu REST API调用还没有熟悉 附： ryu/app/ofctl_rest.py 提供的REST API 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133# REST API## Retrieve the switch stats## get the list of all switches# GET /stats/switches## get the desc stats of the switch# GET /stats/desc/&lt;dpid&gt;## get flows desc stats of the switch# GET /stats/flowdesc/&lt;dpid&gt;## get flows desc stats of the switch filtered by the fields# POST /stats/flowdesc/&lt;dpid&gt;## get flows stats of the switch# GET /stats/flow/&lt;dpid&gt;## get flows stats of the switch filtered by the fields# POST /stats/flow/&lt;dpid&gt;## get aggregate flows stats of the switch# GET /stats/aggregateflow/&lt;dpid&gt;## get aggregate flows stats of the switch filtered by the fields# POST /stats/aggregateflow/&lt;dpid&gt;## get table stats of the switch# GET /stats/table/&lt;dpid&gt;## get table features stats of the switch# GET /stats/tablefeatures/&lt;dpid&gt;## get ports stats of the switch# GET /stats/port/&lt;dpid&gt;[/&lt;port&gt;]# Note: Specification of port number is optional## get queues stats of the switch# GET /stats/queue/&lt;dpid&gt;[/&lt;port&gt;[/&lt;queue_id&gt;]]# Note: Specification of port number and queue id are optional# If you want to omitting the port number and setting the queue id,# please specify the keyword \"ALL\" to the port number# e.g. GET /stats/queue/1/ALL/1## get queues config stats of the switch# GET /stats/queueconfig/&lt;dpid&gt;[/&lt;port&gt;]# Note: Specification of port number is optional## get queues desc stats of the switch# GET /stats/queuedesc/&lt;dpid&gt;[/&lt;port&gt;[/&lt;queue_id&gt;]]# Note: Specification of port number and queue id are optional# If you want to omitting the port number and setting the queue id,# please specify the keyword \"ALL\" to the port number# e.g. GET /stats/queuedesc/1/ALL/1## get meter features stats of the switch# GET /stats/meterfeatures/&lt;dpid&gt;## get meter config stats of the switch# GET /stats/meterconfig/&lt;dpid&gt;[/&lt;meter_id&gt;]# Note: Specification of meter id is optional## get meter desc stats of the switch# GET /stats/meterdesc/&lt;dpid&gt;[/&lt;meter_id&gt;]# Note: Specification of meter id is optional## get meters stats of the switch# GET /stats/meter/&lt;dpid&gt;[/&lt;meter_id&gt;]# Note: Specification of meter id is optional## get group features stats of the switch# GET /stats/groupfeatures/&lt;dpid&gt;## get groups desc stats of the switch# GET /stats/groupdesc/&lt;dpid&gt;[/&lt;group_id&gt;]# Note: Specification of group id is optional (OpenFlow 1.5 or later)## get groups stats of the switch# GET /stats/group/&lt;dpid&gt;[/&lt;group_id&gt;]# Note: Specification of group id is optional## get ports description of the switch# GET /stats/portdesc/&lt;dpid&gt;[/&lt;port_no&gt;]# Note: Specification of port number is optional (OpenFlow 1.5 or later)# Update the switch stats## add a flow entry# POST /stats/flowentry/add## modify all matching flow entries# POST /stats/flowentry/modify## modify flow entry strictly matching wildcards and priority# POST /stats/flowentry/modify_strict## delete all matching flow entries# POST /stats/flowentry/delete## delete flow entry strictly matching wildcards and priority# POST /stats/flowentry/delete_strict## delete all flow entries of the switch# DELETE /stats/flowentry/clear/&lt;dpid&gt;## add a meter entry# POST /stats/meterentry/add## modify a meter entry# POST /stats/meterentry/modify## delete a meter entry# POST /stats/meterentry/delete## add a group entry# POST /stats/groupentry/add## modify a group entry# POST /stats/groupentry/modify## delete a group entry# POST /stats/groupentry/delete## modify behavior of the physical port# POST /stats/portdesc/modify## modify role of controller# POST /stats/role## send a experimeter message# POST /stats/experimenter/&lt;dpid&gt;","categories":[{"name":"SDN","slug":"SDN","permalink":"https://yanghaku.github.io/categories/SDN/"}],"tags":[{"name":"SDN","slug":"SDN","permalink":"https://yanghaku.github.io/tags/SDN/"}]},{"title":"SDN实验环境搭建","slug":"SDN实验环境搭建","date":"2020-02-19T13:20:00.000Z","updated":"2020-02-22T06:02:43.461Z","comments":true,"path":"2020/02/19/SDN实验环境搭建/","link":"","permalink":"https://yanghaku.github.io/2020/02/19/SDN%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","excerpt":"工具选择列表操作系统：ubuntu_19.10 数据平面（虚拟交换机）：OpenvSwitch（OVS）控制器：ryu mininet组网工具：mininet是一个用python实现的，可以很快地模拟出OpenFlow交换机（基于Openvswitch）、host以及自定义各种网络拓扑结构。提供命令行CLI和python的API sflow-rt：sFlow技术是以设备端口为基本单元的数据流随机采样的流量监控技术。sflow分为sflow agent和sflow collector, sflow agent内嵌在网络设备中将采集的信息封装成sFlow报文发送给sflow collector， sflow-rt为 sflow collector实现的一种工具。","text":"工具选择列表操作系统：ubuntu_19.10 数据平面（虚拟交换机）：OpenvSwitch（OVS）控制器：ryu mininet组网工具：mininet是一个用python实现的，可以很快地模拟出OpenFlow交换机（基于Openvswitch）、host以及自定义各种网络拓扑结构。提供命令行CLI和python的API sflow-rt：sFlow技术是以设备端口为基本单元的数据流随机采样的流量监控技术。sflow分为sflow agent和sflow collector, sflow agent内嵌在网络设备中将采集的信息封装成sFlow报文发送给sflow collector， sflow-rt为 sflow collector实现的一种工具。 … 下载系统，安装，更换源清华镜像源下载 ubuntu desktop 19.10VMware安装… 安装之后首先更换源1sudo vi /etc/apt/sources.list改成： 1234567891011#阿里云源deb http://mirrors.aliyun.com/ubuntu/ eoan main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ eoan main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ eoan-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ eoan-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ eoan-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ eoan-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ eoan-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ eoan-backports main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ eoan-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ eoan-proposed main restricted universe multiverse 然后更新系统和软件仓库: 12sudo apt updatesudo apt upgrade 首先安装的软件是vim, 并且设置vim配置12sudo apt install vim vim-gtksudo vim /etc/vim/vimrc.local 添加以下内容 123456789syntax onset smartindentset cindentset autoindentset tabstop=4set shiftwidth=4set softtabstop=4set numberset hlsearch 安装依赖： 1sudo apt install ssh net-tools python python-pip m4 autoconf libtool git 安装mininet1sudo apt install mininet 然后测试 12yb@ubuntu:~$ mn --version2.2.2 安装OpenvSwitch从官网下载最新版本： 123456wget https://www.openvswitch.org/releases/openvswitch-2.12.0.tar.gztar -zxvf openvswitch-2.12.0.tar.gzcd openvswitch-2.12.0/sudo ./boot.shsudo ./configure --prefix=/usr --localstatedir=/var --sysconfdir=/etcsudo make &amp; sudo make install 启动：12export PATH=$PATH:/usr/share/openvswitch/scriptsovs-ctl start 配置数据库：12sudo mkdir -p /usr/local/etc/openvswitchsudo ovsdb-tool create /usr/local/etc/openvswitch/conf.db /usr/share/openvswitch/vswitch.ovsschema 初始化数据库：1sudo ovs-vsctl --no-wait init 最后查看安装状态：1234yb@ubuntu:/var/run/openvswitch$ sudo ovs-vsctl show0e0bf153-77d4-43ff-9795-5085d959712e ovs_version: \"2.12.0\"yb@ubuntu:/var/run/openvswitch$ 安装Ryu安装之前安装之前需要注意pip下载的包的位置的问题：pip下载的时候会保存到用户的 ~/.local/lib/python2.7/site-packets，而当用sudo 运行的时候，包的位置没有包含这个位置，所以就会报错。可以用python -m site看到： 123456789101112131415161718192021222324252627282930313233343536yb@ubuntu:~/Downloads$ python -m sitesys.path = [ '/home/yb/Downloads', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/home/yb/.local/lib/python2.7/site-packages', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages',]USER_BASE: '/home/yb/.local' (exists)USER_SITE: '/home/yb/.local/lib/python2.7/site-packages' (exists)ENABLE_USER_SITE: Trueyb@ubuntu:~/Downloads$ sudo python -m sitesys.path = [ '/home/yb/Downloads', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages',]USER_BASE: '/root/.local' (doesn't exist)USER_SITE: '/root/.local/lib/python2.7/site-packages' (doesn't exist)ENABLE_USER_SITE: True``` 可见两者差别。所以要在安装任何python包之前，将这个用户自己的包位置关掉，就不会出现这个问题了！```bashsudo vim /usr/lib/python2.7/site.py 将ENABLE_USER_SITE的值改为False，即NABLE_USER_SITE = False. 修改后就可以安装了，这里选择从github上面获取1234git clone https://github.com/osrg/ryu.gitcd ryupip install -r tools/pip-requires #安装依赖sudo python setup.py install装完之后可以输入命令ryu-manager查看是否安装成功 安装sflow-rt首先需要安装java环境 1sudo apt install openjdk-8-jre-headless openjdk-8-jdk-headless 然后下载安装sflow-rt1234wget https://inmon.com/products/sFlow-RT/sflow-rt.tar.gztar -zxvf sflow-rt.tar.gzcd sflow-rt./start.sh # 启动然后访问 127.0.0.1:8008/ 可以看到sflow的监控页面，安装成功 可以选择安装sflow-rt的app，可以看官网https://sflow-rt.com/download.php 对每个app的介绍123./get-app.sh sflow-rt flow-trend./get-app.sh sflow-rt mininet-dashboard./get-app.sh sflow-rt ix-metrics 至此工具安装完成 mininet安装目录：/usr/lib/python2.7/dist-packages/mininet Ryu安装目录：/usr/local/lib/python2.7/dist-packages/ryu (可以直接用pip show modules 命令查看安装位置) sflow-rt安装目录就是解压的目录 搭建一个简单的SDN网络首先启动sflow-rt监控1(path_to_sflow-rt)/start.sh 然后启动ryu的内建app：1ryu-manager (path_to_ryu)/app/simple_switch_13.py 最后用mininet组网，设置控制器为ryu（默认端口6653或6633），openflow版本为1.3，交换机为ovs。 1sudo mn --switch ovs,protocols=OpenFlow13 --controller=remote,ip=127.0.0.1,port=6653 --custom sflow-rt/extras/sflow.py --topo=tree,depth=3,fanout=2 pingall，可以看到创建成功12345678910111213141516171819202122232425262728293031b@ubuntu:~$ sudo mn --switch ovs,protocols=OpenFlow13 --controller=remote,ip=127.0.0.1,port=6653 --custom sflow-rt/extras/sflow.py --topo=tree,depth=3,fanout=2*** Creating network*** Adding controller*** Adding hosts:h1 h2 h3 h4 h5 h6 h7 h8 *** Adding switches:s1 s2 s3 s4 s5 s6 s7 *** Adding links:(s1, s2) (s1, s5) (s2, s3) (s2, s4) (s3, h1) (s3, h2) (s4, h3) (s4, h4) (s5, s6) (s5, s7) (s6, h5) (s6, h6) (s7, h7) (s7, h8) *** Configuring hostsh1 h2 h3 h4 h5 h6 h7 h8 *** Starting controllerc0 *** Starting 7 switchess1 s2 s3 s4 s5 s6 s7 ...*** Enabling sFlow:s1 s2 s3 s4 s5 s6 s7*** Sending topology*** Starting CLI:mininet&gt; pingall*** Ping: testing ping reachabilityh1 -&gt; h2 h3 h4 h5 h6 h7 h8 h2 -&gt; h1 h3 h4 h5 h6 h7 h8 h3 -&gt; h1 h2 h4 h5 h6 h7 h8 h4 -&gt; h1 h2 h3 h5 h6 h7 h8 h5 -&gt; h1 h2 h3 h4 h6 h7 h8 h6 -&gt; h1 h2 h3 h4 h5 h7 h8 h7 -&gt; h1 h2 h3 h4 h5 h6 h8 h8 -&gt; h1 h2 h3 h4 h5 h6 h7 *** Results: 0% dropped (56/56 received)mininet&gt; ryu-manager的控制台输出packet in 包 访问本地的 127.0.0.1:8008 ，可以用sflow的app mininet-dashboard看到拓扑和流量监控： 至此简单的SDN实验环境搭建完成。 （附：ubuntu server18.04.4版本安装）其实这些工具都用不到图形界面的，所以说安装server是最省资源的方法。 首先从清华镜像源下载ubuntu18.04.4-server.iso,用vmware新建虚拟机安装安装的时候会选择源，将默认的改成 http://mirrors.aliyun.com/ubuntu/ 即可。 安装后先修改字体（控制台字体太小了，看不清），当然，一直用ssh远程访问也行。1sudo dpkg-reconfigure console-setup弹出之后依次选择 UTF-8，latin1 and latin5 -western Europe and Turkic languages字体，terminusBlod，大小为 11*22 或者别的即可. 安装依赖1sudo apt install vim gcc ssh net-tools python python-pip python-dev m4 autoconf libtool git openjdk-8-jre-headless openjdk-8-jdk-headless uml-utilities python-qt4 python-twisted-conch debhelper python-all 配置vim:sudo vim /etc/vim/vimrc.local添加：123456789syntax onset smartindentset cindentset autoindentset tabstop=4set shiftwidth=4set softtabstop=4set numberset hlsearch 配置python包位置：sudo vim /usr/lib/python2.7/site.py将line76 ， ENABLE_USER_SITE = None 改为 ENABLE_USER_SITE = False 安装mininet：sudo apt install mininet 安装sflow-rt：1234567wget https://inmon.com/products/sFlow-RT/sflow-rt.tar.gztar -zxvf sflow-rt.tar.gzcd sflow-rt./get-app.sh sflow-rt flow-trend # 安装app./get-app.sh sflow-rt mininet-dashboard./get-app.sh sflow-rt ix-metrics./start.sh # 启动 安装ryu：1234git clone https://github.com/osrg/ryu.gitcd ryupip install -r tools/pip-requires #安装依赖sudo python setup.py install 安装ovs： 123456789101112131415161718wget https://www.openvswitch.org/releases/openvswitch-2.12.0.tar.gztar -zxvf openvswitch-2.12.0.tar.gzcd openvswitch-2.12.0/sudo ./boot.shsudo ./configure --prefix=/usr --localstatedir=/var --sysconfdir=/etcmakesudo make install # 运行export PATH=$PATH:/usr/share/openvswitch/scriptsovs-ctl start# 配置数据库sudo mkdir -p /usr/local/etc/openvswitchsudo ovsdb-tool create /usr/local/etc/openvswitch/conf.db /usr/share/openvswitch/vswitch.ovsschema# 初始化数据库：sudo ovs-vsctl --no-wait init 最后查看安装状态：12345yb@sdn-server:~$ sudo ovs-vsctl show[sudo] password for yb:fd6b05e7-0737-4230-9c6e-9d8b71816e02 ovs_version: \"2.12.0\"yb@sdn-server:~$","categories":[{"name":"SDN","slug":"SDN","permalink":"https://yanghaku.github.io/categories/SDN/"}],"tags":[{"name":"SDN","slug":"SDN","permalink":"https://yanghaku.github.io/tags/SDN/"}]},{"title":"SDN架构与实现4--SDN控制平面与控制器","slug":"SDN架构与实现4-SDN控制平面与控制器","date":"2020-02-19T12:25:00.000Z","updated":"2020-02-19T08:53:23.371Z","comments":true,"path":"2020/02/19/SDN架构与实现4-SDN控制平面与控制器/","link":"","permalink":"https://yanghaku.github.io/2020/02/19/SDN%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AE%9E%E7%8E%B04-SDN%E6%8E%A7%E5%88%B6%E5%B9%B3%E9%9D%A2%E4%B8%8E%E6%8E%A7%E5%88%B6%E5%99%A8/","excerpt":"SDN技术将交换设备的控制平面迁移到集中化的控制器中，利用标准化的南向接口替换了交换设备中的控制平面，并在控制器中增加了可编程的北向接口供上层调用。","text":"SDN技术将交换设备的控制平面迁移到集中化的控制器中，利用标准化的南向接口替换了交换设备中的控制平面，并在控制器中增加了可编程的北向接口供上层调用。 南向网络控制技术控制器的网络控制技术主要包括通过南向接口协议进行链路发现、拓扑管理、策略制定、表项下发等。其中链路发现和拓扑管理主要是控制器利用南向接口的上行通道对底层交换设备上报信息进行统一监控而统计的技术，而策略制定和表项下发则是控制器利用南向接口的下行通道对网络设备实施统一控制的技术。 链路发现：链路发现是获得SDN全网信息的关键，由控制器统一完成。SDN控制器主要是使用了LLDP链路层发现协议来进行，通过每个交换机传来的信息，创建出完备的网络拓扑图。 拓扑管理：最主要的就是随时监控和采集网络中SDN交换机的信息，及时反馈网络中的设备工作状态和链路连接状态。为了实现这一目标，控制器需要定时发送LLDP的数据包获知交换机信息。另一个工作是对逻辑组网进行记录，最典型的应用场景是云计算环境下多租户共享网络资源。这些租户网络相关的信息都要在拓扑管理中保存和展现，以反映真实的网络利用状况。 策略制定：流表是SDN交换机进行数据处理的最基本依据，直接影响了数据转发效率和网络的性能。控制器流表的生成算法成了影响控制器智能化水平的关键因素。SDN交换机中的流表机制打破了传统网络中的层次化概念，无论是源MAC等二层信息，还是目的IP等三层信息，都统一封装在一个流表项中。因此，控制器就需要针对不同层次上的网络需求，制定相应的网络转发策略： 对于二层网络数据的转发，传统设备的主要工作是学习MAC地址和基于MAC的转发。而SDN中，MAC学习已经在链路控制中实现，所以只需要以目的MAC为依据，将对应的交换机转发端口号写入相应交换机的流表项即可。 对于三层网络数据的转发，传统设备通常采用“一次路由多次转发”的机制，即交换设备在接受来自源IP的数据包后，查询路由表确定到达目的IP的路由，并通过一定的机制确立源MAC与目的MAC以及转发端口的对应关系，后续在源和目的之间产生的通信由二层模块直接处理。在SDN中，核心是控制器利用相关的路由算法计算出源和目的之间的路由信息，并以IP地址、MAC地址为依据将对应的交换机转发端口写入相应的流表中。 对于四层网络数据的转发，最主要的是额外考虑每个数据包中包含哪个应用协议的TCP/UDP端口信息。以TCP/UDP端口、IP地址、MAC地址为依据，写入对应交换机流表中。 表项下发：SDN流表下发有主动和被动两种模式 主动：在数据包到达交换机之前就进行流表设置，数据包到达的时候交换机已经知道如何处理，消除了数据传输中流表项设置的延迟。 被动：交换机收到一个数据包且没有与之匹配的流表项时，只能将其送给控制器处理。一旦控制器确定后，相关的信息就返回并缓存在交换机上。 北向业务支撑技术通过北向接口，网络业务的开发者能够以软件编程的方式调用局域网、广域网等各种各样的网络资源能力。同时网络资源管理系统可以通过控制器提供的北向接口获知网络资源的工作状态并对网络资源进行调度，实现资源的统一交付，更好地支持云计算等新业务对网络资源的需求。 东西向控制器扩展技术控制器复制对整个SDN的集中化控制，对于把握全局资源视图、改善网络资源交付质量具有非常重要的作用。但控制能力集中化，也使控制器具有了更大的责任，一旦控制器在性能上或安全上得不到保障，随之而来的就是整个SDN的服务能力降级甚至全网瘫痪。另外，从组网架构上来看，单一的控制器也无法应对跨越多个地域的SDN问题。所以需要多台控制器形成的分布式集群，避免单一控制节点造成的可靠性、可扩展性、性能方面的问题。目前用于多个控制器之间的沟通和联系的东西向接口还没有被定义为标准，但是之前的一些集群技术已经可以被用于解决上述的问题。 开源控制器主要的一些开源控制器： 名称 编程语言 简介 Beacon java Stanford大学开发，采用模块化设计 Floodlight java 基于Beacon开发，一个企业级的经典SDN控制器 NodeFlow javascript 基于Nodejs的控制器 NOX C++ 业界第一个SDN控制器 POX python NOX的兄弟版本 Ryu python NTT公司开发，具有丰富的控制器API OpenDaylight java 支持多种南向协议的广义SDN控制平台 RyuRyu是由日本的NTT公司开发的python的开源SDN控制器，代码的模块清晰，可拓展性强。架构与其他的SDN控制器相似，大致分为控制层和应用层。控制层主要包括协议解析、事件系统、基本网络报文库类等。应用层是基于控制层提供的API编写的网络应用，以及支持Ryu和其他系统协同工作的模块。而且提供了REST API和RPC接口，允许外界进程与Ryu进行通信。可以作为OpenStack的插件，也支持和Snort协同合作。 Ryu主要组件： 基本组件 组件名 功能 base.app_manager 对其他组件的管理，由ryu-manager自动调用 controller.dpset 管理of交换机的组件 controller.ofp_handler 对控制器、交换机之间握手、协商过程的处理 controller.ofp_event 完成OF消息-事件的转换，提供北向接口 api controller.controller 控制器组件，管理与of交换机连接的安全通道，接受of消息，调用ofp_event并发布相应的事件 与of协议相关的组件 组件名 功能 ofproto.v_1_X 相应协议版本的参数 ofproto.v_1_X_parser 定义了相应协议版本消息的封装格式 内建应用 组件名 功能 app.gui_topology.gui_topology 拓扑发现的GUI模块 app.simple_vlan 基本的vlan app.tunnel 多种隧道策略 app.simple_switch 简单2层交换机交换策略 其他 组件名 功能 cmd.* 命令行相关功能 lib.* 报文相关的定义，比如IP，TCP等 topology.* 拓扑相关的事件和数据结构，提供对应的API app.rest* 基础的REST API 接口 app.ofp_rest of相关的REST API 至此，基本理论就大体学完了，下面就开始进行实践了！","categories":[{"name":"SDN","slug":"SDN","permalink":"https://yanghaku.github.io/categories/SDN/"}],"tags":[{"name":"SDN","slug":"SDN","permalink":"https://yanghaku.github.io/tags/SDN/"}]},{"title":"SDN架构与实现3--SDN数据平面与交换机","slug":"SDN架构与实现3--SDN数据平面与交换机","date":"2020-02-19T10:25:00.000Z","updated":"2020-02-19T06:32:39.786Z","comments":true,"path":"2020/02/19/SDN架构与实现3--SDN数据平面与交换机/","link":"","permalink":"https://yanghaku.github.io/2020/02/19/SDN%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AE%9E%E7%8E%B03--SDN%E6%95%B0%E6%8D%AE%E5%B9%B3%E9%9D%A2%E4%B8%8E%E4%BA%A4%E6%8D%A2%E6%9C%BA/","excerpt":"传统网络设备的功能模块在生产时就已经固定，只支持有限的用户配置，而不支持用户自定义编程。在传统的路由器和交换机的转发处理都是协议相关的，每个模块都是为了特定的网络协议而设计的，一旦设计完成就只能处理固定格式的网络数据包，无法根据用户需求来支持新的网络协议。所以SDN才有了数控分离的设计，提供了可编程能力。在SDN中，决定网络可编程能力的因素在于数据平面可编程，只有数据平面有了足够的可编程能力，控制平面才能通过南向接口来对网络进行灵活的编程控制。","text":"传统网络设备的功能模块在生产时就已经固定，只支持有限的用户配置，而不支持用户自定义编程。在传统的路由器和交换机的转发处理都是协议相关的，每个模块都是为了特定的网络协议而设计的，一旦设计完成就只能处理固定格式的网络数据包，无法根据用户需求来支持新的网络协议。所以SDN才有了数控分离的设计，提供了可编程能力。在SDN中，决定网络可编程能力的因素在于数据平面可编程，只有数据平面有了足够的可编程能力，控制平面才能通过南向接口来对网络进行灵活的编程控制。 通用的可编程数据平面支持网络用户通过软件编程的方式任意定义数据平面的功能，包括数据包的解析和数据包的处理等功能，可以实现真正意义上的软件定义网络。为了提供更好的拓展性，通用可编程数据平面设备中所有的网络处理模块，包括包解析器、包转发和包调度，都是可以可编程重配置或者协议无关的，都具有足够的可编程能力。理想的转发模型应该具有以下三个条件： 清晰的软硬件接口 简介的硬件接口 灵活有效的功能实现 The McKeown Group在这个基础上定义了一种可编程通用转发抽象模型：OpenFlow Switch。在SDN可编程数据平面的发展过程中，OpenFlow Switch通用转发模型是现在通用可编程数据平面的代表。到目前为止，业界主流的SDN硬件交换机都实现了OpenFlow Switch通用转发模型的支持，还有业界使用最多的开源软件交换机Openvswitch。 通用可编程转发模型OpenFlow Switch将网络数据转发处理抽象成通用的Match-Action过程，同时对网络系统中各种查找表进行了通用化处理，抽象成一种新的通用表转发模型结构。每个流表都可以实现用户定义的网格处理功能，从而实现可编程的网络数据转发处理。这种模型有四个特征： 转发行文由控制平面指定 由基础转发原语组成 支撑高性能和低功耗 避免厂商锁定控制程序 OpenFlow Switch模型主要包括“通用硬件模型”和“通用处理指令”两部分，通用硬件模型由一组网络通用硬件子模型组成。通用处理指令包含了一组用户可编程的网络处理操作和处理指令。 通用硬件模型通用的硬件模型处理流程为：数据包从某个端口进入 $\\rightarrow$ 通用模型的协议解析模块完成包头分析 $\\rightarrow$ 根据分析结果选择对应的流表处理。在流表内部，解析出的数据包会与每个表项进行比较。如果匹配到了，就执行相应的指令，否则就会按照相应的指令丢弃或者转发给控制器。 网络通用的处理指令分为三种类型：操作指令、跳转指令和专用指令。操作指令通常是对数据包的具体操作，比如修改转发丢弃等；跳转指令实现在多个流表直接的跳转；专用指令实现某种特定的网络数据流的处理。完成处理之后，将数据包从某个指定端口发出去。 流水线处理“多级流表”优势：因为现有的交换芯片内部通常有多个查找表，比如二层转发表，三层路由表和访问接入控制等，“多级流表”的概念使得芯片更容易支持，资源利用率也高。多个网络应用会根据不同包头域组合，对数据包进行关联处理。并且单一流表会使表非常大，信息冗余。在支持多级流表的OpenFlow Switch通用硬件模型中，每个数据包在进入流水线之前，都将分配一个对应的操作指令集。然后从第0个流表开始，匹配查找，根据定义的操作传给下一个流表或者执行对数据包的处理。 流表OpenFlow Switch通过流（flow）的概念来描述具有相同特征的数据包集合。然后对于flow的处理，OpenFlow Switch定义了流表项（flow Entry）来处理对应的数据流。每个流表有多个流表项组成，用户通过对这些表项进行编程区分flow，同时定义对应的处理指令。每个流表项主要内容有：匹配域，指令集，计数器，优先级，失效时间，cookie，flags等 匹配域：用来与每个数据包的指定包头标识集合进行比较，包括输入端口，包头标识域和Metadata三部分。 指令集：指定该flow中的数据包的跳转操作，同时也包括对流表项的操作指令 计数器：实时统计与流表项匹配成功的数据包数目信息，是分析用户流量的关键信息 优先级：说明该流表的匹配优先级，当数据包与多个流表项匹配成功时，需要按照优先级来选择出一个流表项。 失效时间： 指定流表项的失效时间。包括硬生存时间和软生存时间。硬生存时间是超过这个时间就被删除。软生存时间是在规定时间内没有匹配到数据包就被删除。 在流水线中，流表的跳转指令只能沿着流水线方向进行处理，而不能回退到之前的流表。当流表没有跳转指令时，就对数据包进行具体的操作。所以流水线的最后一个流表不能有跳转指令，从而停止流水线。 流表子模型本质上是一个面向flow的转发表。 组表组表是一种转发表的抽象子模型，具备给一组端口定义某种指定操作的抽象能力，从而便捷实现组播，负载均衡，重定向等功能。 每个流表项包括：组号（Group Identifier），计数器（Counters），组类型（Group Type），操作桶（Action Buckets）。组类型有四种： 全选类型（All）：执行Action Buckets里所有的操作动作集，可以用来实现网络中的组播和广播功能。对应的flow数据包会直接复制到每个Action Bucket里。如果某个Action Buckets将数据包直接转发给输入端口就不复制这个包。 选择类型（Select）：只选择执行一个Action Buckets的动作集，通常用交换机自己的算法来选择。 间接类型（Indirect）：只能支持一个Action Buckets，用来实现多个流表项或多个组表项指向单一组表ID的情况。 快速恢复类型（Fast Failover）：只执行第一个激活的Action Bucket。能让转发模型自己调整转发操作，不需要每次请求控制器。多用于容灾备份的场景。 组表子模型也是一种转发表，只是表项定义与流表的内容不同。 Meter表Meter表是第三种转发表类型的抽象子模型，其使得OpenFlow Switch模型具备测量Flow的能力，可以用来实现速率控制等简单的Qos服务，也可以实现相对复杂的Qos服务。 每个Meter表项由三个部分：计量标识（Meter Idendifier），计数器（Counters），计量带（Meter Bands）。每一个计量带有bandtype，rate，counters和band type可选参数四部分组成。rate为一个网络数据流的传输速率阈值。Band Type定义了一种对应的包处理方式，通常只有网络数据流当前流量速率超过这个速率阈值时，才会执行BandType的操作。 状态信息表OPenFlow模型里面定义了大量的计数器，分别由流表、流表项、端口、队列、Group、Group Bucket、Meter和计量带维护着。这些计数器合起来就构成了一个状态信息表。其中有一个特殊的计数器Duration计数器，记录流表项、端口、队列、Group和Meter的存活时间，精度通常是纳秒。计数器的实现可以用软件，也可以用硬件。 端口端口子模型是网络设备常见的模型，是其他网络设备和OpenFlow Switch的网络接口，通用硬件模型通过端口连接在一起（逻辑上的连接）。OpenFlow Switch模型定义了物理端口（Physical Port）、逻辑端口（Logical Port）和保留端口（Reserved Port）三种端口类型。所有物理端口、逻辑端口和保留端口中的本地类型统称为标准端口，只有这些端口才能用作网络数据包的输入和输出端口，才能在组表中使用并且拥有端口计数器、端口状态和配置信息。物理端口是物理网络中的真实网络接口，与网络中的物理接口一一对应；逻辑端口是一种抽象的端口，用作描述链路聚合组、隧道和回环接口等逻辑概念；保留端口是OpenFlow Switch模型中预留的虚拟端口类型。 总之，OpenFlow Switch通用硬件模型定义了一组抽象的子模型来描述这个网络通用转发模型。其中包括三种特殊的转发表（流表、组表、Meter表），计数器组成的状态信息表和端口子模型。 通用处理指令OpenFlow Switch通用处理指令包括：网络处理控制指令Instructions，网络数据操作指令Actions和专用网络处理指令三部分。 网络处理控制指令OpenFlow Switch定义的第一种是基于Flow的网络处理流程控制指令Instructions，这种指令控制数据包在通用硬件模型流水线上的处理流程。控制指令有两种： 对Flow数据包的操作指令集的写入，应用删除等修改操作指令，比如写操作（Write-Actions），应用操作指令（Apply-Actions）。 指定flow数据包在多个表中的处理顺序和跳转指令，比如Goto-Table指令。 每个流表项包括多个控制指令，组成对应的指令集和。 操作指令OpenFlow Switch定义的第二种是基于Flow的网络处理操作指令Actions。这种操作指令完成对数据包的丢弃、复制、转发和修改等操作。每一个数据包进入流水线后就分配一个Action Set，用于保存处理数据的动作，其集合中同一类型的动作只有一个。此外还可以是Action List，同一类型的动作数目不受限制。 包含的指令主要有：Output port num 转发到某个端口，Group group id 发送到指定的group表项处理，Drop 丢掉…. 专用指令第三种是基于flow的专用指令。这种专用指令通过一条指令实现特定网络的处理功能。典型有Table Miss指令。Table Miss定义了在流表中匹配不成功时，网络数据包的处理行为。 总之，OpenFlow Switch只是定义了一种通用的可编程转发模型，对于数据包解析协议和包调度模块还不具备编程能力，所以依然有很大的发展空间。 通用的可编程数据平面当下的OpenFlow Switch模型还不具备协议无关网络数据处理，还不能成为完全的通用可编程数据转发模型。P4编程语言框架、POX协议无关转发等，都在不断探索完善中。 白盒交换机白盒交换机（White Box Switch），又称开放网络交换机，只有硬件而软件需要自定义安装，是网络交换机硬件和操作系统解耦合的结果。在网络领域，通常是交换机硬件和操作系统紧紧绑定在一起销售，在SDN架构的推动下，White Box Switch模式使得用户可以自主选择交换机硬件和操作系统。在近几年的SDN发展中，白盒交换机成为了新的发展趋势。","categories":[{"name":"SDN","slug":"SDN","permalink":"https://yanghaku.github.io/categories/SDN/"}],"tags":[{"name":"SDN","slug":"SDN","permalink":"https://yanghaku.github.io/tags/SDN/"}]},{"title":"SDN架构与实现2--SDN南向协议","slug":"SDN架构与实现2--SDN南向协议","date":"2020-02-17T09:25:00.000Z","updated":"2020-02-19T03:11:53.601Z","comments":true,"path":"2020/02/17/SDN架构与实现2--SDN南向协议/","link":"","permalink":"https://yanghaku.github.io/2020/02/17/SDN%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AE%9E%E7%8E%B02--SDN%E5%8D%97%E5%90%91%E5%8D%8F%E8%AE%AE/","excerpt":"SDN南向协议SDN架构中，网络的控制平面和数据平面相分离，通过南向协议进行通信。南向协议提供的可编程能力是SDN可编程能力的决定因素，所以南向协议是SDN最核心、最重要的接口标准之一。南向协议尝试为网络数据平面提供统一的、开放的和具有更多编程能力的接口，使得控制器可以基于这些接口对数据平面设备进行编程控制，指导网络流量的转发等行为。南向协议可以根据可编程能力分为狭义的南向协议和广义的南向协议。狭义的南向协议是具有确切的对数据平面的编程能力，指导数据平面设备的转发操作等行为。典型的是Openflow协议。POF协议和P4协议也属于狭义的南向协议的范围，但是这两个比SDN南向协议更具有通用的抽象能力，能力范围已经超越了狭义南向协议的定义，所以并不能简单归类到这里（分类是完全可编程的南向协议）。广义的南向协议主要是三种类型： 仅具有对数据平面配置能力的南向协议，如：OF-Config，OVSDB，NET-CONF 具有部分可编程能力的协议，如：OpFlex 本来就存在，不限于应用在SDN控制平面和数据平面通信的协议，如：PCEP，XMPP","text":"SDN南向协议SDN架构中，网络的控制平面和数据平面相分离，通过南向协议进行通信。南向协议提供的可编程能力是SDN可编程能力的决定因素，所以南向协议是SDN最核心、最重要的接口标准之一。南向协议尝试为网络数据平面提供统一的、开放的和具有更多编程能力的接口，使得控制器可以基于这些接口对数据平面设备进行编程控制，指导网络流量的转发等行为。南向协议可以根据可编程能力分为狭义的南向协议和广义的南向协议。狭义的南向协议是具有确切的对数据平面的编程能力，指导数据平面设备的转发操作等行为。典型的是Openflow协议。POF协议和P4协议也属于狭义的南向协议的范围，但是这两个比SDN南向协议更具有通用的抽象能力，能力范围已经超越了狭义南向协议的定义，所以并不能简单归类到这里（分类是完全可编程的南向协议）。广义的南向协议主要是三种类型： 仅具有对数据平面配置能力的南向协议，如：OF-Config，OVSDB，NET-CONF 具有部分可编程能力的协议，如：OpFlex 本来就存在，不限于应用在SDN控制平面和数据平面通信的协议，如：PCEP，XMPP 狭义SDN南向协议狭义南向协议的代表是Openflow，2008年Nick McKeown教授在论文中第一次介绍了这个协议，论文介绍了Openflow的原理，包括Openflow交换机和Openflow控制器的设计。Openflow是第一个SDN控制平面和数据平面交互的通信接口，也是目前最流行的SDN南向协议。 在Openflow 1.0版本中定义了Openflow交换机，流表和Openflow通道，到了1.3版本又增加了组表和Meter表这两种新表。 Openflow表流表流表（Flow Table）是交换机用于存储流表项的表。在Openflow1.0版本中仅有一张流表（单流表）。由于单流表可以支持的程序逻辑太简单，无法满足复杂的业务逻辑，所有在Openflow1.1版本中又增加了多级流表的概念。多级流表使数据包的处理逻辑划分成多个子逻辑，分成多个表来处理，使数据包的处理变成了一条流水线。流表中由匹配域、指令集和计数器三个主要部分及其他部分组成（优先级、计时器等）。网络数据表进入交换机之后会匹配流表中的流表项，匹配到同一条流表的数据包称为数据流Data Flow，简称Flow。匹配域用于区分不同的数据流，匹配成功之后执行对应的指令，完成对数据的处理。 匹配域原先叫做包头域，（1.0协议里）包括12个元组：入端口（Ingress Port），源MAC地址（Ether Source），目的MAC地址（Ether Des），以太网类型（Ether Type），VLAN ID（VLAN ID），VLAN优先级（VLAN Priority），源IP地址（IP Src），目的IP地址（IP Dst），IP协议（IP Proto），IP TOS位（IP Tos bits），TCP/UDP源端口（TCP/UDP Src Port）,TCP/UDP目的端口（TCP/UDP Dst Port） 组表组表（Group Table）是定义一组动作，且这组动作可被多条流表项共同使用，从而实现组播、负载均衡、聚合等功能。结构有：组表号，类型，计数器和动作桶。 组表的存在降低了流表的逻辑复杂度，也减少了流表的存储空间。 Meter表Meter表（Meter Table）用于计量和限速，其结构有：计量表号，计量带和计数器。Meter表项针对流制定对应的限速等规则，从而实现丰富的Qos功能。Meter表是面向流的，更细致灵活。 Openflow通道Openflow通道是控制器和交换机通信的通道，通道中转发的数据为Openflow消息（Openflow报文）。 Openflow报文分为 Controller-to-Switch、Asynchronous、Symmetric三大类。Controller-to-Switch类型的报文主要是由控制器初始化并发送给交换机，Asynchronous类型报文主要是交换机异步上报给控制器的报文，Symmetric类报文是无需等待对方请求、双方都可以任意发送的报文。 Controller-to-Switch报文Controller-to-Switch 报文是控制器初始化并下发给交换机的报文类型。其可能会要求交换机回复对应的报文。主要类型： Features：Features类型的报文主要分Request和Reply两种，其中控制器可以主动初始化并发送Feature_Request 报文，请求交换机回复其特性信息，交换机收到后将通过Feature_Reply报文回复交换机的特性和交换机端口特性信息。通常控制器会在交换机的Openflow连接建立完成之后马上发送一个请求报文来获取交换机的特征信息。 Configuration： 其包含请求、回复和设置三种报文。控制器可以设置和请求交换机的配置信息，交换机则需执行配置和回复配置报文。 Modify-State：读取状态信息，由控制器发出，用于获取交换机的状态信息，包括流表、组表、Meter表及端口的统计信息。 Packet-out：由控制器发出，用于将数据包发送到交换机的指定端口。一般用于相应Packet-in报文的处理，经常跟在Flow-mod报文之后，用于指挥交换机将缓存数据发送或直接发送数据。Packet-out还需要携带指导数据处理的动作集，如果动作集为空则交换机会将数据包丢弃。 Barrier：Barrier Request/Reply 用于确保操作顺序执行。控制器可以向交换机发送Request报文，交换机收到后将request报文之前的报文处理完成之后，再处理Barrier Request请求。回复控制器一个Barrier Reply报文，其报文ID和请求报文一致，告知控制器在Barrier Request报文之前到来的报文已经处理完成。类似于设置一个障碍或触发器，确保动作执行顺序，保持策略的一致性。 Role-Request： 用于控制器请求其自身在交换机端的角色，也用于设置控制器的角色。一般用于交换机在与多控制器有连接的场景。 Asynchronous-Configuration：异步配置报文可以用来配置异步报文的过滤器，从而使得在多控制器场景下，控制器可以选择性过滤异步报文，只接收感兴趣的报文。 Asynchronous报文Asynchronous报文是由交换机异步发送给控制器的报文，无须等待控制器请求。交换机通过异步报文告知控制器新数据包的到达和交换机状态的改变。主要类型： Packet-in：将数据包发给控制器。在支持单流表的Openflow协议中，触发Packet-in 的原因可能是流表项的动作指导，也可能是因为匹配不到流表项。但在高版本的多级流表设计下，将默认下发一条Table-Miss流表项。其匹配域均为空，任何报文都能匹配成功。Table-Miss作用是将匹配其他流表失败的数据发给控制器。若交换机配置信息中指示将数据包缓存在交换机上，则Packet-in报文还将携带着指定长度的数据包数据及其在交换机上缓存的Buffer_id，携带的数据包默认长度是128字节。若交换机不缓存数据包，则Packet-in会携带全部数据并发送给控制器。Packet-in通常会触发Packet-out报文或者Flow-mod报文。 Flow-Removed：当OFPFF_SEND_FLOW_REM标志位被置位的时候，交换机将会在流表项失效时通知控制器流表项被移除的消息。触发流表项失效的原因可以是控制器主动删除或者流表项超时。 Port-status：当端口配置或者状态变化时，用于告知控制器端口状态发生改变。 Pole-status：当控制器角色发生变换时，交换机告知控制器其角色变换。 Controller-Status：当Openflow连接发生变化时，通知控制器。 Flow-monitor：告知控制器流表的改变。控制器可以设置一系列监视器来追踪流表的变化。 Symmetric报文控制器和交换机双方都可以发送，无须得到对方的许可或请求。主要类型： Hello：Openflow通道建立初期，用于协商版本等内容。 Echo：Echo Request/Reply 任意一方发出，每个Request都需要Reply回复，主要是保持连接的活性，也可以支持携带消息内容，用于时延或带宽测试。 Error：错误报文用于告知对方错误。一般多用于交换机告知控制器请求发生的错误。 Experimenter： 实验报文是报文功能范围之外的标准方式，可以用于实验场景。 Openflow通信流程交换机和控制器建立完socket通信之后，会相互发送Hello报文，协商版本协议。当版本协议协商之后，控制器会向交换机下发Feature Requet报文，交换机需回复Feature Reply报文。控制器根据交换机支持的特性，可以完成交换机的相关配置。配置完成之后，进入正常的通信状态。如果Openflow版本支持多流表，控制器还会下发Table-Miss流表项到交换机。当交换机匹配流表失败或者匹配到Table-Miss时，交换机会将其Packet-in到控制器，控制器根据当前逻辑选择回复Packet-out或者下发Flow-mod指导交换机处理数据流。如果配置了Flow-Removed标志位，则当流表过期时，交换机会向控制器回复Flow-Removed报文。其他异步报文发生在任意时刻。为了保持连接活性，会周期性地发出Echo报文。 广义的SDN南向协议OF-Config在Openflow协议的规范中，控制器需要和配置完成的交换机进行通信。交换机正常工作前需要对其功能、特性及资源进行配置才能正常工作。这些配置超出了Openflow协议的范围。OF-Config（Openflow Management and Configuration Protocol）协议就是一种Openflow 交换机配置协议。作为Openflow的伴侣协议，OF-config很好填补了Openflow协议之外的内容。在Openflow协议的SDN框架中，需要如OF-Config这样的配置协议来完成交换机的配置工作，包括配置控制器信息等内容。当交换机和控制器建立连接之后，将通过Openflow协议来传递信息。OF-Config是对Openflow协议的补充，但是设计动机、设计目的和实现方式都不一样。有些Openflow逻辑交换机的属性均可以通过Openflow协议和OF-Config协议来配置，所以两个协议有一些重叠的功能。 OVSDBOVSDB（The Open vSwitch Database Management Protocol, OVS的数据库管理协议）是专门用于Openvswitch的管理和配置的协议。OVSDB和OF-Config类似，都是Openflow交换机配置协议，但两者也有区别：OVSDB仅用于OVS的配置和管理，而OF-Config可以用于所有支持OpenFlow的软件和硬件的交换机。随着虚拟机及Docker等虚拟化技术在数据中心及实验环境中越来越普及，OVS作为虚拟机和Docker与物理网络通信的关键节点越来越重要，所以专门用来配置OVS的协议OVSDB在未来也越来越重要。 NETCONF为了弥补SNMP的不足，IETF提出的一个基于XML的NETCONF协议，具有很强的数据描述能力和良好的扩展性。因为在网络配置方面高效，所以成为了许多网络设备的配置协议，被多种SDN控制器支持。但是它无法指导交换机进行数据转发处理，它的定位还是和OVSDB，OF-Config类似。对于传统设备而言，NETCONF可以配置之后即可工作，对于SDN设备而言，还需要Openflow等协议来指导交换机的数据交换功能。 OpFlexOpFlex是思科提出来的一个可扩展的SDN南向协议，用于控制器和数据平面设备直接交换网络策略。OpFlex是一种声明式控制协议，而Openflow则是一种命令式控制。声明式控制是只通知对象要达到一种要求状态，但是没有规定其通过指定的方式去达到这个状态。本质上是一种SDN南向协议，但是其具有的可编程能力不强，且采用OpFlex架构的终端依然是底层的智能设备，所以OpFlex只能归类于广义的SDN南向协议范畴。 XMPPXMPP（Extensible Messaging and Presence Protocol）是一种以XML为基础的开放式即时通讯协议。由于其自身具有良好的扩展性，从而可以被灵活应用到即使通讯、网络设备管理等多种场合。XMPP不是专门为SDN设计的，因为其良好的扩展性，逐渐成为SDN南向协议的一种。优点是可以统一管理传统设备和SDN设备。用户的网络可能存在大量的传统设备，采用兼容性良好的XMPP可以统一管理，从而保护用户的已有资产，这是XMPP作为南向协议最大优势之一。不过功能粒度相比于Openflow还很粗。 PCEPPECP（Path Computation Element Communication Protocol）是由IETF提出的路径计算单元通信协议，常为流量工程提供路径计算服务。PECP的设计具有很好的弹性和可扩展性，易于拓展。PCEP把路径计算的控制逻辑从转发设备抽离到远端，实现了部分的数据平面和控制平面的分离。通过远端服务器的软件编程，可以指导底层路由或转发设备实现数据的转发和路由，所以也属于一种广义的SDN南向协议。但PECP可编程能力还不完善，也不是专门为SDN设计的。 完全可编程的南向协议POFPOF（Protocol Oblivious Forwarding）是由华为宋浩宇等人提出来的SDN南向协议，是一种实现方式。与OpenFlow相似，在POF定义的架构中分为控制平面的POF控制器和数据平面的POF转发元件。POF是协议无关的协议，在POF架构中，POF交换机没有协议的概念，仅仅是在POF控制器的指导下通过{offset,length}来定位数据、匹配并执行对应的操作。此举使交换机在不关心网络协议的情况下完成网络数据的处理，使得在支持新协议的时候无须岁交换机进行升级，只需要升级控制平面即可。 在原先的OpenFlow协议里，1.0版本12个匹配域，1.3版本40个匹配域。随着技术的发展，还会有更多的协议需要支持，那匹配域也需要增加。不断增加的匹配域使得OpenFlow协议越来越复杂，而且设备厂家需要开发出新的交换机来支持新的协议。原先OpenFlow数据平面和控制平面分离不够彻底，数据平面交换机依然需要掌握协议的语义等控制信息才能完成数据匹配。 POF通过通用指令集来实现协议无关转发的设计，使交换机具有完全的可编程能力。控制器通过南向协议对交换机进行编程，包括协议解析和对应数据流处理规则的编程。当网路中需要支持新协议时，只需要通过控制器进行编程就可实现，大大缩短了网络创新的周期。而对于运营商或者服务提供商而言，在添加新的网络服务的时候不用再联系厂商，也不用购买新的交换设备了。 P4P4是由Pat Bosshart等人提出的“协议无关数据包处理编程语言”。定义了一系列语法，也开发出了P4的编译器，支持对P4转发模型的协议解析过程和转发过程进行编程定义，实现了真正意义上的协议无关可编程网络数据平面。和POF相似，只不过侧重点不同。POF通过{offset,length}来确定待匹配数据，强调协议无关，而P4不仅有底层高度抽象的协议无关指令集，更侧重于网络数据平面编程语言的建模。P4和POF的出现，给网络带来更强大的可编程能力，是必然趋势，是不可阻挡的。","categories":[{"name":"SDN","slug":"SDN","permalink":"https://yanghaku.github.io/categories/SDN/"}],"tags":[{"name":"SDN","slug":"SDN","permalink":"https://yanghaku.github.io/tags/SDN/"}]},{"title":"SDN架构与实现1--SDN介绍","slug":"SDN架构与实现1--SDN介绍","date":"2020-02-17T06:27:00.000Z","updated":"2020-02-17T09:07:13.216Z","comments":true,"path":"2020/02/17/SDN架构与实现1--SDN介绍/","link":"","permalink":"https://yanghaku.github.io/2020/02/17/SDN%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AE%9E%E7%8E%B01--SDN%E4%BB%8B%E7%BB%8D/","excerpt":"（SDN介绍）","text":"（SDN介绍） 前置知识网络基础理论知识基础的理论知识就是计网的知识啦首先是OSI七层模型（理想模型），TCP/IP网络模型 分层： 物理层：规定着为传输数据所需要的物理链路创建，维持，拆除，而提供的具有机械，电子，功能和规范的特性，主要是关心如何传递信号。 数据链路层：主要是规定相邻节点的数据帧封装和差错控制。 网络层：负责路由将报文分组转发给目标主机或网络。 传输层：负责对报文进行重组，建立应用程序之间端到端的连接。 应用层：向用户提供应用程序。 主要的协议：以太网，IP，ARP，RARP，ICMP，TCP，UDP，DNS，DHCP等 设备：物理层(L1)：中继器（repeater），集线器（hub）链路层(L2)：网桥（bridge），交换机（switch）网络层(L3)：路由器（router） 交换机交换机是最重要的信息交换网络设备，主要功能有：学习设备的MAC地址二层转发三层转发ACL（访问控制列表，基于包过滤的访问控制技术）Qos（服务质量）消除回路 随着SDN和NFV的发展，越来越多的功能放在了虚拟交换机上，现在最常用的虚拟交换机是Openvswitch。 三层交换机和路由器三层交换机也和传统的二层交换机不一样，支持三层转发（路由功能），是工作在网络层的。与路由器的区别： 三层交换机同时支持二层三层转发，而路由器只支持三层转发 三层交换机的功能不如路由器，路由器还会有防火墙等各种功能，更适合网络复杂的场景下，而交换机的主要功能还是数据交换。 三层交换机的转发性能比路由器好，非常适合大型局域网内的数据路由和交换。 传统的网络架构及其缺陷传统的网络是分布式的架构，没有控制中心，每台设备都包含独立的控制平面和数据平面：这里的分布式是指，用于路由器计算的控制平面和报文转发的数据平面，都位于同一台设备中。路由计算和拓扑变化后，每台设备都要重新计算路由，每台设备都是独立收集网络信息，独立计算，只关心自己的选路。这种的弊端就是所有的设备在计算路径的时候缺乏统一性。传统的通常部署网管系统作为管理平面，控制平面和数据平面分布在每一台设备上。 现在主要面临的是四个问题： 传统网络部署管理困难不同厂商的网络设备混杂在一起使用，但是不同的厂商的设备都是通过不同的方式去部署，命令也不一致，每台设备都要单个部署。管理这些设备，大多都是通过网管软件来管理，生成网络的拓扑图，知道哪一台设备在哪里，出现故障能够报警。但是更多的是侧重于监控，而不是分配和部署，也就是说，如果知道故障在哪里，还是需要人为去修理。 分布式架构出现性能瓶颈典型的分布式架构，都是通过设备之间互相交换信息，然后每个进行独立计算。但是现在流量剧增，设备也是数量不断增多，当有设备变动的时候，路由收敛的时间越来越长，路由的效率也越来越低。 流量控制非常难流量均衡负载难，流量路径的灵活调整能力不足。而且不能可视化，网管软件只能监视故障，而不能检查全局全网的链路状态。 无法对设备进行编程传统的网络设备，工作方式都是厂商决定的，用户自定义的转发策略等都不能灵活改变。买来设备的时候，里面支持的协议都已经被订好，不能通过安装软件的方式增加设备的功能。就算可以也要通过重装OS等复杂的手段来实现。 总之，传统网络出现的许多局限性，促使了SDN的诞生。 SDN定义SDN（Software Defined Networking，软件定义网络） 是一种新兴的基于软件的网络架构及技术，其最大的特点就是在于具有松耦合的控制平面和数据平面、支持集中化的网络状态控制、实现底层网络设施对上层应用透明。上面只是其中的一个定义，SDN有着几个组织对它的不同定义，但是本质上没有太大的差别，都强调了SDN拥有数据平面和控制平面分离的特点，也都强调了支持通过软件编程对网络进行控制的能力。SDN主要有三个特征： 网络开放可编程：SDN建立了新的网络抽象模型，为用户提供了一套完整的通用API，使用户可以在控制器上编程实现对网络的配置、控制和管理，从而加快网络业务的部署的进程。 控制平面和数据平面分离：控制平面和数据平面不再相互依赖，两者可以独立完成体系结构的演进，双方只要规定一个统一开放的接口进行通信即可。控制平面和数据平面的分离是SDN架构区别于传统网络体系结构的重要标志，是网络获得更多可编程能力的架构基础。 逻辑上的集中控制：主要是指对分布式网络状态的集中统一管理。在SDN架构中，控制器会担负起收集和管理所有网络状态信息的重任。逻辑的集中控制为软件定义网络功能提供了架构基础，也为网络自动化管理提供了可能。 因此，只要符合以上三个特征的网络都叫软件定义网络。在这三个特征中，控制平面和数据平面分离为逻辑集中控制创造了条件，逻辑集中控制为开放可编程控制提供了架构基础，而网络开发可编程才是SDN的核心特征。 SDN体系结构SDN网络体系结构主要包括SDN网络应用、北向接口、SDN控制器、南向接口和SDN数据平面五个部分。 SDN网络应用层实现了对应的网络功能应用，这些应用通过调用SDN控制器的北向接口，实现对网络数据平面设备的配置、管理和控制。 北向接口是SDN控制器与网络应用程序之间的开放接口，它将数据平面资源和状态信息抽象层统一的开放编程接口。 SDN控制器是SDN的大脑，也称作网络操作系统。控制器不仅要通过北向接口给上层网络应用提供不同层次的可编程能力，还要通过南向接口对SDN数据平面进行统一配置、管理和控制。SDN控制器负责整个网络的运行，是提升SDN网络效率的关键。当前有许多基于openflow控制协议的开源控制器的实现，比如NOX，POX等，他们都有各自的特色设计，能够实现链路发现、拓扑管理、表项下发等SDN运行的基本操作。 南向接口是SDN控制器与数据平面之间的开放接口。SDN控制器通过南向接口对数据平面进行编程控制，实现数据平面的转发等网络行为。当前，最知名的南向接口就是ONF提出的OPenflow协议了。同时ONF还提出OF-CONFIG协议，用于对SDN交换机进行远程配置和管理，其目标都是为了更好地对分散部署的SDN交换机实现集中控制。 SDN数据平面包括基于软件实现的和基于硬件实现的数据平面设备。数据平面设备通过南向接口接收来自控制器的指令，并按照这些指令完成特定的网络数据处理。同时SDN数据平面设备也可以通过南向接口给控制器反馈网络配置和运行时的状态信息。SDN交换机是SDN网络中负责具体数据转发处理的设备。和传统网络交换机路由器一样，都是根据数据的某些特征项与表项进行对比，确定相应的处理，与传统设备不同的是，SDN交换机中的表项是由远程控制区统一下发的。因此SDN交换机可以忽略控制逻辑的实现而只专注于表项的数据处理。因为考虑和传统网络混合工作，所以支持混合模式的交换机是设备层技术的一个研发焦点。SDN交换机一个重要的应用场景是虚拟化的环境，所以SDN交换机会有软件硬件两种形态。比如OVS（Openvswitch）就是一个虚拟的开源交换机，在虚拟化组网中产生了巨大的作用。","categories":[{"name":"SDN","slug":"SDN","permalink":"https://yanghaku.github.io/categories/SDN/"}],"tags":[{"name":"SDN","slug":"SDN","permalink":"https://yanghaku.github.io/tags/SDN/"}]},{"title":"基于内容的个性化推荐系统设计与实现","slug":"基于内容的个性化推荐系统","date":"2020-02-12T03:22:00.000Z","updated":"2020-02-13T08:03:12.578Z","comments":true,"path":"2020/02/12/基于内容的个性化推荐系统/","link":"","permalink":"https://yanghaku.github.io/2020/02/12/%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E4%B8%AA%E6%80%A7%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/","excerpt":"因为项目的需要，里面加一个小型的推荐系统的模块，就找了一些资料，实现了基于内容的一个推荐系统。 原理基于内容相似度的推荐：就是把与你喜欢看的文章内容相似的文章推荐给你。 优势：无冷启动的问题，只要用户产生了初始的历史数据，就可以开始进行推荐计算。而且随着用户的浏览记录数据的增加，这种推荐一般也会越来越准确。","text":"因为项目的需要，里面加一个小型的推荐系统的模块，就找了一些资料，实现了基于内容的一个推荐系统。 原理基于内容相似度的推荐：就是把与你喜欢看的文章内容相似的文章推荐给你。 优势：无冷启动的问题，只要用户产生了初始的历史数据，就可以开始进行推荐计算。而且随着用户的浏览记录数据的增加，这种推荐一般也会越来越准确。 判断两篇内容相似用TFIDF 算法，提取出每篇新闻的 (关键词,TFIDF值) 词数对 TFIDF 计算：首先分词 然后词频： 词频（TF） = \\frac{某个词在文章出现次数}{文章总词数}逆文档频率（需要一个语料库） 逆文档频率（IDF） = \\log(\\frac{语料库中的文档数}{包含该词的文档数+1})最后： TFIDF = TF * IDFTF-IDF与一个词在文档中的出现次数成正比，与该词在整个语言中的出现次数成反比，反应了这个词在文章中的重要程度。 两篇文章的相似度就可以利用余弦定理来算： Similarity(A,B) = \\frac{\\sum_{i\\in A\\cap B} TFIDF_A[i] * TFIDF_B[i] }{ \\sqrt{\\sum{TFIDF_A[i]*TFIDF_A[i]}} + \\sqrt{\\sum{TFIDF_B[i]*TFIDF_B[i]}} }构建用户的喜好关键：维护用户喜好的关键词表 ，维护 (关键词, 喜好程度) 键值对 获得：根据用户的点赞、收藏记录 做法： 用户浏览了某个文章，利用TF-IDF 取得这篇文章的 （关键词,IFIDF值）键值对，并将这个存入用户的喜好关键词列表中。（如果已经有了，那就将值叠加，表示用以加强用户对该关键词的感兴趣程度） 考虑的问题：用户喜好会不会不断更新？会不会导致推荐结果收敛到用户以前特别喜欢的几个关键词上？ 考虑到这个问题，可以为关键词列表设置一个衰减系数 $\\lambda$ , 定期对用户的所有TFIDF值进行更新衰减，减少关键词的收敛倾向。 用户的喜好与内容的匹配程度计算有了用户的喜好关键词表： { keyword1:val1, keyword2:val2,………} 某条文章的关键词表： {keyword1: val1, keyword2: val2,………} 用户的喜好表也看作一篇文章，两者的匹配值也是用余弦定理（上面的similarity）来计算。 对所有新的文章进行计算，将拟合度最高的N个推荐给用户 如果可推荐的太少：为用户设定一个文章推荐的最小值 N， 若不够 N ， 就用热点（近期被点击最多的文章）作为补充 架构令维护三个数据表： 文章的关键词表 article_keyword 用户喜爱的关键词表 user_keyword 用户推荐的文章表 article_recommend 设定更新周期（比如1天），那么可以在每日凌晨某一时刻的时候进行： 将最近1天更新的所有文章分析，更新其关键词表 将用户的喜好关键词表进行时间的衰减 然后将最近1天的收藏记录和点赞记录，更新有活动记录用户的关键词表 最后更新有活动记录用户推荐的文章表 实现1.定时任务首先增加 “spring-task.xml” 配置文件，配置spring的定时任务 在web.xml 增加这个配置文件1234567&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt; classpath:spring-mybatis.xml classpath:spring-task.xml &lt;!-- 增加的值 --&gt; &lt;/param-value&gt; &lt;/context-param&gt; 编辑spring-task.xml 文件，使其支持注解 1234567891011121314151617181920&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:task=\"http://www.springframework.org/schema/task\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-3.0.xsd\"&gt; &lt;!-- 配置spring 定时任务的配置文件 --&gt; &lt;!--配置包扫描--&gt; &lt;context:component-scan base-package=\"edu.study.util.timer\" /&gt; &lt;!-- 定时任务配置 scheduler 方式 注解 --&gt; &lt;task:executor id=\"executor\" pool-size=\"5\"/&gt; &lt;task:scheduler id=\"scheduler\" pool-size=\"10\"/&gt;&lt;!-- 配置线程池--&gt; &lt;task:annotation-driven executor=\"executor\" scheduler=\"scheduler\"/&gt;&lt;/beans&gt; 然后在 edu.study.util 里面新建一个包 timer ， 在timer包内增加TimerJob 类 TimerJob.java:(其中里面用的ContentBaseRecommend类就是将要实现的关键类) 1234567891011121314151617181920212223package edu.study.util.timer;import edu.study.util.recommend.ContentBasedRecommend;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.scheduling.annotation.Scheduled;import org.springframework.stereotype.Component;import java.util.Date;@Componentpublic class TimerJob &#123; /** * 定时任务的类 */ @Autowired ContentBasedRecommend contentBasedRecommend; @Scheduled(cron = \"0 0/2 * * * ?\")//每隔2分钟执行一次 public void recommendRefresh()&#123; // 刷新上次更新至今这个时间段的推荐 contentBasedRecommend.refresh(); &#125;&#125; 2.基于内容的推荐算法实现(为了省事，全部写在了一个类里面) 新建一个包 edu.study.util.recommend然后新建一个类 ContentBasedRecommend.javaContentBasedRecommend.java（具体实现看代码和注释）: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317package edu.study.util.recommend;import edu.study.dao.*;import edu.study.model.*;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import java.util.*;@Componentpublic class ContentBasedRecommend &#123; // 需要用到的数据库服务 @Autowired ArticleMapper articleMapper; @Autowired ArticleAgreeMapper articleAgreeMapper; @Autowired ArticleCollectionMapper articleCollectionMapper; @Autowired ArticleKeywordMapper articleKeywordMapper; @Autowired UserKeywordMapper userKeywordMapper; @Autowired ArticleRecommendMapper articleRecommendMapper; private Date lastRefreshDate;//维护上次更新的时间 private static final int ARTICLE_KEYWORD_MAX_NUM = 100;// 设置一个文章的关键词上限 private static final int USER_KEYWORD_MAX_NUM = 1000;//设置存储的用户关键词的上限 private static final int RECOMMEND_NUM = 20; // 设置每个用户推荐的文章个数 private static final double AUTO_DEC_NUM = 0.9; //设置每天衰减的系数 private static final double lambda = 1.5; //设置收藏的权重 对于 点赞的权重的倍数 /** *根据lastrefreshTime ~ 至今 这个时间段的活动记录，刷新推荐 * 并将lastrefreshTime 更新到现在 * */ public void refresh()&#123; if(lastRefreshDate == null)&#123;//如果上次更新时间没有实例化，那就创建一个最早的时间 lastRefreshDate = new Date(); lastRefreshDate.setTime(0); &#125; System.err.println(\"last time: \" + lastRefreshDate); Date nowRefreshTime = new Date();//本次的更新时间 System.err.println(\"now: \"+ nowRefreshTime); // 1. 将时间段内更新的文章的关键词更新 articleKeywordRefresh(); // 2. 根据两次时间差，将所有用户的喜好衰减更新 userKeywordAutoDec(lastRefreshDate,nowRefreshTime); // 3. 根据时间段内的活动记录，将活动的用户的关键词更新 HashMap&lt;String,HashMap&lt;String,Double&gt; &gt; usersKeyword = userKeywordRefresh(); if(usersKeyword.size() == 0)&#123;// 如果这段时间没有产生用户行为，就直接退出 lastRefreshDate = nowRefreshTime; return; &#125; List&lt;ArticleKeyword&gt; articleKeywordList = articleKeywordMapper.selectAll(); // 预处理所有的文章的关键词保存下来 HashMap&lt;Integer,List&lt;Keyword&gt; &gt;articleKeyword = new HashMap&lt;&gt;(); for(ArticleKeyword item : articleKeywordList)&#123; if(articleKeyword.containsKey(item.getArticleId()))&#123; articleKeyword.get(item.getArticleId()).add(new Keyword(item.getKeyword(),item.getTfidf())); &#125; else&#123; List&lt;Keyword&gt; keywordList = new ArrayList&lt;&gt;(); keywordList.add(new Keyword(item.getKeyword(),item.getTfidf())); articleKeyword.put(item.getArticleId(),keywordList); &#125; &#125; articleKeywordList.clear(); // 预处理出来 每个关键词列表的 平方和的平方根 （余弦定理的分母部分） HashMap&lt;String,Double&gt; userDiv = new HashMap&lt;&gt;(); HashMap&lt;Integer,Double&gt; articleDiv = new HashMap&lt;&gt;(); for(Map.Entry&lt;String,HashMap&lt;String,Double&gt;&gt; entry: usersKeyword.entrySet())&#123; double sum=0; for(Double val: entry.getValue().values())&#123; sum += val*val; &#125; userDiv.put(entry.getKey(),Math.sqrt(sum)); &#125; for(Map.Entry&lt;Integer,List&lt;Keyword&gt; &gt; entry: articleKeyword.entrySet())&#123; double sum=0; for(Keyword x : entry.getValue())&#123; sum += x.getTfidf() * x.getTfidf(); &#125; articleDiv.put(entry.getKey(),Math.sqrt(sum)); &#125; List&lt;ArticleRecommend&gt; articleRecommends = new ArrayList&lt;&gt;(); //开始推荐计算 for(Map.Entry&lt;String,HashMap&lt;String,Double&gt; &gt; userEntry: usersKeyword.entrySet())&#123; //外层循环遍历每个用户 articleRecommends.clear(); for(Map.Entry&lt;Integer,List&lt;Keyword&gt;&gt; articleEntry: articleKeyword.entrySet())&#123; //内层循环遍历每篇文章 double score = similarity(userEntry.getValue(),articleEntry.getValue()); if(score &gt; 0.00001)&#123;// 非零就加入推荐列表里 score /= (userDiv.get(userEntry.getKey()) * articleDiv.get(articleEntry.getKey())); articleRecommends.add(new ArticleRecommend(userEntry.getKey(),articleEntry.getKey(),score)); &#125; &#125; // 删除数据库中原先的推荐信息 articleRecommendMapper.deleteByUsername(userEntry.getKey()); // 如果推荐的列表大于需要推荐的个数，就排序，添加前面推荐值高的 // 保存到数据库中 if(articleRecommends.isEmpty())continue; if(articleRecommends.size() &gt; RECOMMEND_NUM)&#123; sortRecommendList(articleRecommends); articleRecommendMapper.insertList(articleRecommends.subList(0,RECOMMEND_NUM)); &#125; else articleRecommendMapper.insertList(articleRecommends); &#125; // 最后将lastRefreshTime 更新成本次更新的时间 lastRefreshDate = nowRefreshTime; &#125; /** * 将lastrefreshTime ~ 至今 时间段的文章的关键词更新 */ private void articleKeywordRefresh()&#123; List&lt;Article&gt; articleList = articleMapper.selectByModifyTime(lastRefreshDate); for(Article article : articleList)&#123; // 对于每个文章，分析出关键词列表 List&lt;Keyword&gt; keywordList = TFIDF.getTFIDF(article.getTitle(),article.getContent(),ARTICLE_KEYWORD_MAX_NUM,articleMapper); // 使用sql批量修改 if(!keywordList.isEmpty())articleKeywordMapper.replaceInto(article.getArticleId(),keywordList); &#125; &#125; /** *根据规定时间段的活动记录，将用户的关键词更新 * 并且将涉及到的用户更新后的值返回（以便为这些用户推荐） */ private HashMap&lt;String,HashMap&lt;String,Double&gt; &gt; userKeywordRefresh()&#123; // 分为两部分：收藏的文章 和 点赞的文章 // 其中收藏的文章的权重为点赞的文章的 lambda 倍 HashMap&lt;String,HashMap&lt;String,Double&gt; &gt; record = new HashMap&lt;&gt;(); // 记录涉及到的每个用户的keyword表，最后一起更新到数据库 // 处理过程中keyword 保存为hashmap ，便于合并（降低查找复杂度） // 1. 文章收藏 List&lt;ArticleCollection&gt; articleCollectionList = articleCollectionMapper.selectByTime(lastRefreshDate); if(articleCollectionList != null) &#123; for (ArticleCollection articleCollection : articleCollectionList) &#123; List&lt;Keyword&gt; articleKeywordList = articleKeywordMapper.selectByArticleId(articleCollection.getArticleId()); if(articleKeywordList == null || articleKeywordList.isEmpty())continue; if (record.containsKey(articleCollection.getUsername())) &#123; // 如果已经有了就合并 HashMap&lt;String,Double&gt; tmp = record.get(articleCollection.getUsername()); for(Keyword articleKeyword: articleKeywordList)&#123; if(tmp.containsKey(articleKeyword.getKeyword())) &#123; tmp.put(articleKeyword.getKeyword(), tmp.get(articleKeyword.getKeyword()) + articleKeyword.getTfidf() * lambda); &#125; else tmp.put(articleKeyword.getKeyword(),articleKeyword.getTfidf()*lambda); &#125; record.put(articleCollection.getUsername(), tmp); &#125; else&#123; HashMap&lt;String,Double&gt; tmp = new HashMap&lt;&gt;(); for(Keyword articleKeyword: articleKeywordList)&#123; tmp.put(articleKeyword.getKeyword(),articleKeyword.getTfidf()*lambda); &#125; record.put(articleCollection.getUsername(), tmp); &#125; &#125; &#125; // 2. 文章点赞 List&lt;ArticleAgree&gt; articleAgreeList = articleAgreeMapper.selectByTime(lastRefreshDate); if(articleAgreeList != null) &#123; for (ArticleAgree articleAgree : articleAgreeList) &#123; List&lt;Keyword&gt; articleKeywordList = articleKeywordMapper.selectByArticleId(articleAgree.getArticleId()); if(articleKeywordList == null || articleKeywordList.isEmpty())continue; if (record.containsKey(articleAgree.getUsername())) &#123; // 如果已经有了就合并 HashMap&lt;String,Double&gt; tmp = record.get(articleAgree.getUsername()); for(Keyword articleKeyword: articleKeywordList)&#123; if(tmp.containsKey(articleKeyword.getKeyword())) &#123; tmp.put(articleKeyword.getKeyword(), tmp.get(articleKeyword.getKeyword()) + articleKeyword.getTfidf()); &#125; else tmp.put(articleKeyword.getKeyword(),articleKeyword.getTfidf()); &#125; record.put(articleAgree.getUsername(), tmp); &#125; else&#123; HashMap&lt;String,Double&gt; tmp = new HashMap&lt;&gt;(); for(Keyword articleKeyword: articleKeywordList)&#123; tmp.put(articleKeyword.getKeyword(),articleKeyword.getTfidf()); &#125; record.put(articleAgree.getUsername(), tmp); &#125; &#125; &#125; // 将增加的关键词 与 用户原先的合并 // 然后将更新的键值 保存到数据库中 for(HashMap.Entry&lt;String,HashMap&lt;String,Double&gt; &gt; entry : record.entrySet())&#123; List&lt;Keyword&gt; userKeywordList = userKeywordMapper.selectByUsername(entry.getKey()); if(userKeywordList != null) &#123; for (Keyword keyword : userKeywordList) &#123; // 如果已经有就合并 if (entry.getValue().containsKey(keyword.getKeyword())) &#123; entry.getValue().put(keyword.getKeyword(), entry.getValue().get(keyword.getKeyword()) + keyword.getTfidf()); &#125; else entry.getValue().put(keyword.getKeyword(), keyword.getTfidf()); &#125; &#125; //将每个用户对应的关键词的map 以列表的形式存下来(方便插入数据库) if(userKeywordList != null )userKeywordList.clear(); else userKeywordList = new ArrayList&lt;&gt;(); for(HashMap.Entry&lt;String,Double&gt; keyWordEntry: entry.getValue().entrySet())&#123; userKeywordList.add(new Keyword(keyWordEntry.getKey(),keyWordEntry.getValue())); &#125; if(userKeywordList.isEmpty())continue; if(userKeywordList.size() &gt; USER_KEYWORD_MAX_NUM) &#123;// 如果超过了规定的数，就删除影响最小的 sortKeyWordList(userKeywordList); while (userKeywordList.size() &gt; USER_KEYWORD_MAX_NUM)&#123; entry.getValue().remove(userKeywordList.get(userKeywordList.size()-1).getKeyword()); userKeywordList.remove(userKeywordList.size()-1); &#125; &#125; // 最后将此保存到数据库中 userKeywordMapper.replaceInto(entry.getKey(),userKeywordList); &#125; return record; &#125; /** * 将关键词列表从大到小排序 * @param keywordList 关键词列表 */ private void sortKeyWordList(List&lt;Keyword&gt; keywordList)&#123; Collections.sort(keywordList, new Comparator&lt;Keyword&gt;() &#123;// 使用内部类自定义排序规则 @Override public int compare(Keyword o1, Keyword o2) &#123; // 按照TFIDF值从大到小排序 if(o2.getTfidf() - o1.getTfidf() &gt; 0)return 1; else if(o2.getTfidf() - o1.getTfidf() == 0)return 0; return -1; &#125; &#125;); &#125; /** * 排序 * @param articleRecommendList 推荐列表 */ private void sortRecommendList(List&lt;ArticleRecommend&gt; articleRecommendList)&#123; Collections.sort(articleRecommendList, new Comparator&lt;ArticleRecommend&gt;() &#123; @Override public int compare(ArticleRecommend o1, ArticleRecommend o2) &#123; if(o2.getSimilarity() - o1.getSimilarity() &gt; 0)return 1; else if(o2.getSimilarity() - o1.getSimilarity() == 0)return 0; return -1; &#125; &#125;); &#125; /** * * @param hashMap 用户的关键词表 * @param keywordList 文章的关键词表 * @return 返回两者的相似度 (余弦定理的上半部分) */ private double similarity(HashMap&lt;String,Double&gt; hashMap,List&lt;Keyword&gt; keywordList)&#123; double ans=0; for(Keyword keyword: keywordList)&#123; if(hashMap.containsKey(keyword.getKeyword()))&#123; ans += keyword.getTfidf() * hashMap.get(keyword.getKeyword()); &#125; &#125; return ans; &#125; /** * 用户的兴趣随时间衰减值 */ public void userKeywordAutoDec(Date from,Date to)&#123; double day = to.getTime() - from.getTime(); day /= (1000 * 60 * 60 * 24 ); //两者相隔的天数 double dec = Math.pow(AUTO_DEC_NUM , day); userKeywordMapper.mulAll(dec); &#125;&#125; 3.TFIDF 算法实现(将分词和TFIDF都写在了一个类里面了) 在包 edu.study.util.recommend 里面新建一个类 TFIDF.java TFIDF需要两个部分： 分词（计算词频），语料库（计算逆文档频率） 分词这里使用的是Stanford CoreNLP， 是由The Stanford Natural LanguageProcessing Group斯坦福大学自然语言处理团队开发的多个NLP工具之一。这个NLP工具非常强大，支持多种编程语言，支持分析多种自然语言，能够进行句法语法分析，远不止分词这点功能。~(这里使用这个工具真的有点大材小用的感觉)~github地址：https://github.com/stanfordnlp/CoreNLP文档地址：https://stanfordnlp.github.io/CoreNLP/index.html 直接使用maven构建工具下载即可，在 “pom.xml” 的&lt;dependencies&gt;节点里面添加： 1234567891011&lt;dependency&gt; &lt;groupId&gt;edu.stanford.nlp&lt;/groupId&gt; &lt;artifactId&gt;stanford-corenlp&lt;/artifactId&gt; &lt;version&gt;3.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;edu.stanford.nlp&lt;/groupId&gt; &lt;artifactId&gt;stanford-corenlp&lt;/artifactId&gt; &lt;version&gt;3.9.2&lt;/version&gt; &lt;classifier&gt;models&lt;/classifier&gt;&lt;/dependency&gt; 这里只加了英文的处理。如果想添加中文或者其他语言的支持，另外再加几个包即可。 主要是使用分词和词性的还原,词性标注 ，比如apples-&gt;apple, created -&gt; create 等然后只将有用的名词，某些动词，形容词，副词等作为关键词（也省去了停顿词的过滤）实现可以看下面的TFIDF.java 中的 cut函数 语料库语料库是个头疼的问题，暂时没有找到，而且每个行业的文本背景不一样，不适合都用通用的IDF语料库，所以就暂时将现有的article数据表当做语料库（这样语料库也是在不断更新扩大中） TFIDF实现其中只提供一个静态接口为推荐算法调用 实现代码 TFIDF.java: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980package edu.study.util.recommend;import edu.stanford.nlp.simple.Document;import edu.stanford.nlp.simple.Sentence;import edu.study.dao.ArticleMapper;import edu.study.model.Keyword;import java.util.*;public class TFIDF &#123; public static List&lt;Keyword&gt; getTFIDF(String title, String content, int keywordNum, ArticleMapper articleMapper)&#123; List&lt;String&gt; words = cut(content); words.addAll(cut(title)); int total = words.size();//总词数 HashMap&lt;String,Double&gt; tfidf = new HashMap&lt;&gt;(); // 首先计算词频 TF for(String word:words)&#123; if(tfidf.containsKey(word))&#123; tfidf.put(word,tfidf.get(word)+1); &#125; else tfidf.put(word,1.0); &#125; words.clear();// 不用的马上清空释放内存 for(Map.Entry&lt;String,Double&gt; entry:tfidf.entrySet())&#123; entry.setValue(entry.getValue() / total ); &#125; // 然后计算逆文档频率 double articleTotal = articleMapper.countAll();//总文档个数 for(Map.Entry&lt;String,Double&gt; entry: tfidf.entrySet())&#123; int num = articleMapper.countLike(\"% \"+entry.getKey()+\" %\") + 1;//包含该词的文档数 entry.setValue(entry.getValue() * Math.log(articleTotal/num)); &#125; // 将计算后的保存为Keyword的列表 List&lt;Keyword&gt; keywords = new ArrayList&lt;&gt;(); for(Map.Entry&lt;String,Double&gt; entry: tfidf.entrySet())&#123; keywords.add(new Keyword(entry.getKey(),entry.getValue())); &#125; tfidf.clear();// 不用的清空释放内存 if(keywords.size() &gt; keywordNum)&#123;// 如果大于给定的个数，就排序,取前面重要的 Collections.sort(keywords, new Comparator&lt;Keyword&gt;() &#123; @Override public int compare(Keyword o1, Keyword o2) &#123; double diff = o1.getTfidf() - o2.getTfidf(); if(diff &lt; 0)return 1; else if(diff == 0)return 0; return -1; &#125; &#125;); keywords.subList(keywordNum,keywords.size()).clear();// 将超过的部分删掉 &#125; return keywords; &#125; private static List&lt;String&gt; cut(String content)&#123;// 分词 Document document = new Document(content); List&lt;String&gt; res = new ArrayList&lt;&gt;(); for(Sentence sentence: document.sentences())&#123; // 可作为关键词的词性： 名词，形容词, 动词 // 名词：NN,NNS,NNP（专有名词）,NNPS, NT(时间名词),NP（名词短语），NR（固有名词） FW（外来词） // 形容词：JJ* , 副词： RB* // 动词： VB* int len = sentence.words().size(); for(int i=0;i&lt;len;++i)&#123; String tag = sentence.posTag(i); if(tag.charAt(0)=='N' || tag.contains(\"VB\") || tag.contains(\"FW\") || tag.contains(\"JJ\") || tag.contains(\"RB\"))&#123; // 将词元添加进列表中 res.add(sentence.lemma(i)); &#125; &#125; &#125; return res; &#125;&#125; LAST最后，这个简易的基于内容的推荐系统就算实现了（作为整个系统的一个小模块）因为时间紧，就写了一天的样子吧，也没有具体的测试推荐的效果，可能会有很多的小bug（以后还是有可能维护更新的）具体可以看项目里代码：https://github.com/yanghaku/java-ssm","categories":[],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://yanghaku.github.io/tags/Spring/"},{"name":"TFIDF","slug":"TFIDF","permalink":"https://yanghaku.github.io/tags/TFIDF/"}]},{"title":"机器学习入门-西瓜书学习笔记（2）模型评估与选择","slug":"周志华机器学习笔记2模型评估与选择","date":"2020-02-07T12:14:00.000Z","updated":"2020-02-12T03:42:12.389Z","comments":true,"path":"2020/02/07/周志华机器学习笔记2模型评估与选择/","link":"","permalink":"https://yanghaku.github.io/2020/02/07/%E5%91%A8%E5%BF%97%E5%8D%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/","excerpt":"","text":"训练误差与过拟合训练误差分类错误的样本数占样本总数的比例称为“错误率”（error rate）。即在m个样本中有a个样本分类错误，则错误率$E = a/m*100% $。相应的，“1-错误率”称为“精度”（accuracy）。更一般地来说，学习器实际预测输出与样本的真实输出之间的差异称为“误差”（error），学习器在训练集上的误差称为“训练误差”（training error）或“经验误差”（empirical error），在新样本上的误差称为“泛化误差”（generalization error）。 过拟合过拟合（overfitting）：把训练样本训练得太好的时候，很可能把训练样本自身的一些特点当做了所有潜在样本都会具有的一般性质，这样导致泛化性能下降。（学习能力太强）欠拟合（underfitting）：与过拟合相对，指对训练样本的一般性质尚未学好。（学习能力太差） 评估方法一般都是通过实验测试的方式来对学习器的泛化误差进行评估，用“测试集”上测得的“测试误差”（testing error）来作为泛化误差的近似。测试集应尽可能与训练集互斥，因为我们要测试的是泛化能力，就像考试出原题的话是测不出学生的“举一反三”能力的。 当只有一个包含 $m$ 个样例的数据集 $D = \\{(x_1,y_1),(x_2,y_2),…,(x_m,y_m)\\}$ 的时候，可以经过一些方法的适当处理来产生训练集$S$ 和测试集$T$: 留出法“留出法”（hold-out）是直接将数据集D划分成两个互斥的集合，其中一个集合作为训练集S，另一个作为测试集T，即：$S\\cupT=D,S\\capT=\\varnothing$。在S上训练出模型之后，用T来评估其测试误差，作为对泛化误差的估计。 比如一个二分类的任务，D有1000个样本，将其划分成S（700个）和T（300个），用S训练后，如果模型在T上有90个样本分类错误，那么其错误率为(90/300)*100% = 30%, 相应的精确度为 1-30%=70%。 updating","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://yanghaku.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://yanghaku.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"机器学习入门-西瓜书学习笔记（1）绪论","slug":"周志华机器学习笔记1绪论","date":"2020-02-03T05:19:00.000Z","updated":"2020-02-04T13:14:33.539Z","comments":true,"path":"2020/02/03/周志华机器学习笔记1绪论/","link":"","permalink":"https://yanghaku.github.io/2020/02/03/%E5%91%A8%E5%BF%97%E5%8D%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%E7%BB%AA%E8%AE%BA/","excerpt":"作为一个对人工智能机器学习领域一无所知的小白，看到许多大神都在推荐周志华老师的《机器学习》这本书来入门。我也找到了这本书，想把这本书研究透彻，借助这本书迈进这个陌生的领域。正所谓不动笔墨不读书，我要在学习的同时，把读到的想到的学到的都记下来，才能更好地真正理解。希望能像前辈大神们那样，坚持读完这本书（并记下属于自己的西瓜书笔记）。就像书里说的那句这学期狠下功夫，基础概念弄得清清楚楚，算法作业也是信手拈来，这门课成绩一定差不了！加油!奥力给！ 基本概念","text":"作为一个对人工智能机器学习领域一无所知的小白，看到许多大神都在推荐周志华老师的《机器学习》这本书来入门。我也找到了这本书，想把这本书研究透彻，借助这本书迈进这个陌生的领域。正所谓不动笔墨不读书，我要在学习的同时，把读到的想到的学到的都记下来，才能更好地真正理解。希望能像前辈大神们那样，坚持读完这本书（并记下属于自己的西瓜书笔记）。就像书里说的那句这学期狠下功夫，基础概念弄得清清楚楚，算法作业也是信手拈来，这门课成绩一定差不了！加油!奥力给！ 基本概念 机器学习（machine learning）是致力于通过计算的手段，利用“经验”来改善系统自身的性能的一门学科。在计算机系统中，“经验”通常以“数据”的形式存在，所以机器学习研究的主要内容就是通过这些“数据”来产生模型的算法，也就是学习算法（learning algorithm）。也就是 原始数据（经验）\\xrightarrow{学习算法} 模型学习之后应用解决问题： 新的情况（经验没有的）\\xrightarrow{学习算法产生的模型} 对应的结果或判断这个模型泛指从数据中学到的结果。有的文献用模型来指全局性的结果（比如一棵决策树），用模式来指局部性的结果（比如一条规则）。 T.M.Mitchell在1997年所著的Machine Learning给出了更形式化的定义：假设用P来评估计算机程序在某任务类T上的性能，若一个程序通过利用经验E在T任务上获得了性能改善，则我们就说关于T和P，该程序对E进行了学习。 基本术语 数据集（data set）：进行机器学习需要的数据所有记录的集合。其中每一条记录是关于一个事件或者对象的一个描述，称为一个“示例”（instance）或“样本”（sample）。 属性 ： 反映事件或者对象在某方面的表现或性质的事项，称为“属性”（attribute）或“特征”（feature）。 属性值：属性上的取值称为“属性值”。 属性空间：属性张成的空间，称为“属性空间”（attribute space），“样本空间”或“输入空间”。 特征向量：由于空间中的每一个点对应一个坐标向量，因此我们也把一个样本称为特征向量（feature vector）。 维数：一个样本的特征的个数称为维数（dimensionality）。 比如一个西瓜（色泽=青绿,根蒂=蜷缩,敲声=浊响）这条记录就是示例或样本。所有的西瓜示例组成的集合就是数据集。“色泽”，“根蒂”，“敲声”就是属性。“青绿”，“蜷缩”，“浊响”就是对应的属性值。把西瓜的“色泽”，“根蒂”，“敲声”作为三个坐标轴，则他们张成一个用于描述西瓜的三维空间，每个西瓜都能在这个空间里找到属于自己的坐标位置。这个西瓜样本也叫做一个特征向量：(青绿,蜷缩,浊响)就是在样本空间对应的坐标。 在这里我的理解是数据集就像数据库里面的一张数据表，表里每一行记录是其中的一个样本，每一列就是对象的一个属性，对应的值也就是属性值。或者用面向对象的方法理解，把研究的对象的某些特征提取出来作为类的属性。每一个样本也就是一个类的实例，所有对象的集合就是数据集。 一般地，令$D = \\{ x_1,x_2,x_3,…,x_m \\} $ 表示包含 $m$个样本的数据集，每个示例由 $d$ 个属性描述， 则每个样本 $x_i = (x_{i1},x_{i2},x_{i3},…,x_{id})$ 是 $d$ 维样本空间 $\\chi$ 的一个向量($x_i \\in \\chi$), 其中 $x_{ij}$ 是 $x_i$ 在第 $j$ 个属性上的取值，样本$x_i$的维数为$d$。 学习/训练：从数据中通过某种学习算法学得模型的过程称为“学习”（learning）或者“训练”（training）。 训练过程中使用的数据称为“训练数据”（training data），其中每一个样本称为一个“训练样本”（training sample），训练样本组成的集合叫做“训练集”（training set）。 学习所得的模型对应了关于数据某种潜在的规律，因此亦成为“假设”；这种规律自身，则称为“真相”或“事实”（ground-truth）。学习的过程就是为了找出或逼近真相。 要学得一个能够“预测”（prediction）的模型，还需要获得训练样本的“结果”信息。 比如$(色泽=青绿,根蒂=蜷缩,敲声=浊响) \\Rightarrow 好瓜$ 标记：样本结果的信息称为“标记”（label），比如上面的“好瓜”就是标记。 样例：有了标记结果的样本，称为“样例”（example）。 标记空间：所有标记的集合，称为“标记空间”或“输出空间”。 一般地，用$(x_i,y_i)$ 表示第 $i$ 个样例，其中 $y_i \\in Y$是示例 $x_i$ 对应的标记，$Y$ 是标记空间。 如果预测的是离散值，则此类学习任务称为“分类”（classification）。如果预测的是连续值，则此类学习任务称为“回归”（regression）。 比如预测瓜是“好瓜”还是“坏瓜”这就是分类，预测瓜的成熟度为“0.90”，“0.95”这种就是“回归”。 对于只涉及两个类别的分类，称为“二分类”（binary classification）任务，通常一个类称为“正类”（positive class），另一个类称为“反类”（negative class）。对于涉及多个类别的分类，称为“多分类”（multi-class classification）任务。 一般地，预测任务是希望通过对训练集 $\\{ (x_1,y_1),(x_2,y_2),(x_3,y_3),…,(x_m,y_m)\\}$进行学习，建立一个从输入空间$\\chi$到输出空间$Y$的映射$f:\\chi\\rightarrow Y$.二分类的任务通常令$Y=\\{-1,+1\\}$ 或 $\\{0,1\\}$, 对于多分类的任务$|Y| \\gt 2$，对于回归任务，$Y = R$（即为实数集）。 学得模型之后，使用其进行预测的过程称为“测试”（testing），被预测的样本称为“测试样本”（testing sample）。测试样本的集合称为“测试集”（testing set）。 训练学得$f$之后，对测试样本$x$，就可以得到预测标记$y = f(x) $. 除了预测任务之外，我们还可以对训练集做“聚类”（clustering），即对训练集中的样本分为若干组，每一组称为一个“簇”（cluster）。这些自动形成的簇可能对应一些潜在的概念划分，有助于我们了解数据内在的规律，能为更深入地分析数据建立基础。 比如将西瓜分为“浅色瓜”，“深色瓜”或者“大瓜”，“小瓜”。 在聚类学习中，像例子上的“浅色瓜”这种概念是我们事先不知道的，而是通过学习得到了这些概念。而且学习过程中使用的训练样本通常都不拥有标记信息。 根据训练数据是否拥有标记信息，学习任务可以大致分为两大类：“监督学习” （supervised learning）和 “无监督学习” （unsupervised learning）。监督学习的代表就是分类和回归，无监督学习的代表就是聚类。 机器学习的目标是使得学得的模型很好地适用于“新样本”，而不是仅仅在训练样本里工作得很好。（预测任务对新样本预测的结果的也要很准确，聚类学习学得的簇划分在新样本上也要适用）。 学得模型适用于新样本的能力，称为“泛化”（generalization）能力。具有强泛化能力的模型能很好地适用于整个的样本空间。 训练集（特殊），训练之后适用于测试集（一般），也就是模型从特殊到一般的能力。 所以说，尽管训练集只是样本的很小的采样，我们仍希望它能很好地反映出样本空间的特性，否则就很难期望在训练集上学得的模型能在整个样本空间上都工作得很好。假设样本空间中全部服从一个未知的$D$分布，我们训练样本越多，那么得到的关于$D$的信息就越多，就越有可能通过学习获得具有强泛化能力的模型。 假设空间概念学习科学推理的两个基本手段：归纳与演绎。归纳是从特殊到一般的“泛化”过程，演绎是从一般到特殊的“特化”过程。“从样例中学习”显然是一个归纳的过程，因此亦成为“归纳学习”（inductive learning）。归纳学习有狭义和广义之分。广义的归纳学习就是从样例中学习，而狭义的归纳学习则要求从训练数据中学得概念（concept）（也称作“概念学习”或“概念形成”）。概念学习技术目前研究、应用都特别少，因为要学得泛化性能好且语义明确的概念实在太困难了，现实常用的技术大多都是产生一个黑箱模型而不是一个明确语义的概念（广义的归纳学习）。（当然，了解概念学习还是对机器学习的学习有帮助的） 概念学习中最基本的就是布尔概念学习，即对“是”，“不是”这样的可表示为0/1布尔值的目标概念的学习。比如我们得到了一个这样的数据集： 编号 色泽 根蒂 敲声 好瓜 1 青绿 蜷缩 浊响 是 2 乌黑 蜷缩 浊响 是 3 青绿 硬挺 清脆 否 4 乌黑 稍蜷 沉闷 否 这里要学习的目标就是“是不是好瓜”，假设由“色泽”，“根蒂”，“敲声”这三个因素完全确定，那么我们学习的目标就是“好瓜是色泽?、根蒂?、敲声?的瓜” 这样的概念。用布尔表达式表示是：“好瓜 $\\leftrightarrow$ (色泽=?) $\\land$ (根蒂=?) $\\land$ (敲声=?)”。我们的任务就是通过对这个训练集的学习，将前面的三个“？”确定下来。 注：如果只是将训练集里面的内容记住，以后再见到一模一样的瓜就能判断，但是对于没见过的瓜就没有了判断能力，这“记住样本”是所谓的“机械学习”或“死记硬背式学习”。这已经和我们的“泛化”的目的相背离了。这和我们人类的学习一样，死记硬背是学不到真正的东西，学不到解决问题的能力的，只有培养举一反三的能力，灵活运用才能是真正的学习。 假设空间学习的过程可以看作是枚举所有的假设的过程，搜索出那些能将训练集中的瓜判断正确的假设，也就是能和所有的训练集数据匹配的假设。所有的假设组成的空间称为假设空间。假设空间及其大小规模是由假设的表示决定的。比如西瓜的例子：“好瓜 $\\leftrightarrow$ (色泽=?) $\\land$ (根蒂=?) $\\land$ (敲声=?)”。如果色泽的取值有两种：“青绿”、“乌黑”，根蒂的取值有两种：“蜷缩”、“稍蜷”，敲声的取值有两种：“浊响”、“沉闷”。因为每一种属性有可能会取什么值都合适，我们用通配符“*”来表示这种取值。还有一种可能是无论这三种属性取什么值都没有“好瓜”存在，我们用“$\\varnothing$”表示这种假设。这样，假设空间的规模大小就是：$(2+1)*(2+1)*(2+1)+1 = 28$ 。 在西瓜的这个大小为28的假设空间里面，有1个是$\\varnothing$,另外27个则是{ “青绿”，“乌黑”，“*” }和 { “蜷缩”，“稍蜷”，“*” } 和 { “浊响”，“沉闷”，“*” } 的组合。 可以用很多策略对这个假设空间进行搜索，比如自顶向下，从特殊到一般，从一般到特殊等。搜索过程中可以不断删除与正例不一致的假设，最终会得到与训练集一致的所有假设，这就是我们学得的结果。在现实问题中，我们的假设空间规模通常非常大，但学习是基于有限的样本训练集进行的，因此可能会有多个假设与训练集一致。这些假设构成的集合称为“版本空间”（version space）。 比如说上面的西瓜问题，搜索后得到了3个满足的假设，也就是版本空间为：(色泽=*,根蒂=蜷缩,敲声=*)(色泽=*,根蒂=*,敲声=清脆)(色泽=*,根蒂=蜷缩,敲声=清脆) 归纳偏好上一节获得的版本空间会带来一个麻烦：有多个和训练集一致的假设，但他们面对新样本的时候却会产生不同的输出。然而，对于一个具体的机器学习的算法而言，它必须产生一个模型，也就是说必须从里面选择出一个。这时候，学习算法本身的“偏好”就起到了关键作用。 例如，若我们的算法喜欢“尽可能特殊”的模型，那么我们就会选择“好瓜$\\leftrightarrow$ (色泽=*,根蒂=蜷缩,敲声=清脆)”;若我们的算法喜欢“尽可能一般”的模型，并且由于某种原因更“相信”根蒂，那么它会选择“好瓜$\\leftrightarrow$ (色泽=*,根蒂=蜷缩,敲声=*)”。 机器学习在学习过程中对某种类型假设的偏好，称为“归纳偏好”（inductive bias），或者简称为“偏好”。 任何一个有效的机器学习算法必有其归纳偏好，否则它将会被假设空间中看似在训练集上“等效”的假设所迷惑，而无法产生确定的学习结果。 归纳偏好可以看作是学习算法自身在一个可能很庞大的假设空间中对假设进行选择的启发式或“价值观”。对于偏好的制定者来说，归纳偏好对应了学习算法中做出的“什么样的模型更好”的假设，这个假设是否成立，归纳偏好是否与问题本身匹配，大多数直接决定了算法是否取得好的性能。脱离具体的问题，空泛地谈论“什么学习算法更好”毫无意义，因为若考虑所有潜在的问题，则所有学习算法都一样好。要谈论算法的相对优劣，必须要针对具体的学习问题，在某些问题上表现好的学习算法，在另一些问题上却可能不尽如人意，学习算法自身的归纳偏好与问题是否相配，往往会起到决定性的作用。 EOF 西瓜书pdf下载链接 链接：https://pan.baidu.com/s/1-NKceuYl-3J-zxStrva6pQ提取码：hvis","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://yanghaku.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://yanghaku.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"Xamarin.Android 运行原理","slug":"Xamarin.Android运行原理","date":"2020-02-02T01:25:00.000Z","updated":"2020-02-02T07:20:24.256Z","comments":true,"path":"2020/02/02/Xamarin.Android运行原理/","link":"","permalink":"https://yanghaku.github.io/2020/02/02/Xamarin.Android%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86/","excerpt":"这篇文章主要内容：Xamarin.Android应用的体系结构Xamarin.Android应用怎么运行在Android系统中的。MCW和ACWXamarin.Android应用包的结构 前置知识：Android操作系统的基础知识 概述在Android原生的开发中，主要运行的是Java或Kotlin编译后的字节码（.dex）每个应用单独分配一个ART虚拟机，运行在linux内核之上。 对于其他语言做的应用在Android平台运行，像c/c++这种静态编译的语言，可以直接编译成二进制码，通过JNI（java本地接口）与java通信（调用操作系统的API），直接运行在Library层即可（因为这一层是c/c++实现的，所以这一层也提供了原生c/c++的API供调用）。 而Xamarin是用C#开发的语言，C#和java一样，也是即时编译（JIT）语言，编译成中间语言（IL）之后需要在 .NET虚拟机上运行（在移动端是Mono虚拟机）。Android操作系统本身就没有C#的运行环境，而C#不能直接编译成二进制机器码，所以要融入Android，还需要在每个应用里带着 .NET运行时（Mono虚拟机）。这样C#才能在Android系统里运行。","text":"这篇文章主要内容：Xamarin.Android应用的体系结构Xamarin.Android应用怎么运行在Android系统中的。MCW和ACWXamarin.Android应用包的结构 前置知识：Android操作系统的基础知识 概述在Android原生的开发中，主要运行的是Java或Kotlin编译后的字节码（.dex）每个应用单独分配一个ART虚拟机，运行在linux内核之上。 对于其他语言做的应用在Android平台运行，像c/c++这种静态编译的语言，可以直接编译成二进制码，通过JNI（java本地接口）与java通信（调用操作系统的API），直接运行在Library层即可（因为这一层是c/c++实现的，所以这一层也提供了原生c/c++的API供调用）。 而Xamarin是用C#开发的语言，C#和java一样，也是即时编译（JIT）语言，编译成中间语言（IL）之后需要在 .NET虚拟机上运行（在移动端是Mono虚拟机）。Android操作系统本身就没有C#的运行环境，而C#不能直接编译成二进制机器码，所以要融入Android，还需要在每个应用里带着 .NET运行时（Mono虚拟机）。这样C#才能在Android系统里运行。 其实Android本身就是软件叠层的方式构建的操作系统，Android上没有支持C#运行的环境，应用安装的时候自己带上就好了。（就举个简单的栗子：windows本身不带着JRE，而用Java语言写的程序在windows上需要JRE来运行，那么我开发Java应用的时候直接在应用里打包一个给自己专门用的JRE，不就支持所有的Windows操作系统了~ ） 这只是简单来说，其实具体还得解决开发的时候操作系统的API调用等等各种问题。 体系结构先放一个官网文档里的架构图： 这张图是Xamarin.Android应用在Android平台上运行的架构图。右边的部分是原生的Android应用在Android系统上的架构图。左边是Xamarin.Android项目在对应层里面添加的运行依赖东西。首先就是在ART的同一层添加了Mono虚拟机（c语言实现的），运行在Linux之上。项目里面java编译的字节码通过ART执行，c#编译的字节码通过Mono虚拟机来执行。应用运行的时候，两个虚拟机在Linux内核之上并行运行的。 Xamarin.Android应用需要包装打包Mono虚拟机，所以产生的.apk文件比原生开发出来的要大。而且应用运行的时候，比原生应用多运行一个虚拟机，效率自然就低了不少。 两者通信：当Java代码运行的时候需要调用C#写好的代码的时候，就需要ART通过ACW来使Mono去运行。对于Xamarin.Android开发人员来说，C#的部分可以调用 .NET API（主要是C#语言的部分），也可以通过一些库来直接访问Linux操作系统的设备。但是Android操作系统大多数的访问（比如电话，音频等）都是java的API来访问的（右边的Java API Framework层），所以才有MCW来调用这些功能。简单来说，ACW是java代码运行的时候去调用C#代码的桥梁，而MCW是C#的代码去调用java代码的桥梁。 MCW 和 ACWMCW（Managed Callable Wrappers）：托管可调用包装器ACW（Android Callable Wrappers）：安卓可调用包装器 ACW: Android callable wrappers are a JNI bridge which are used any time the Android runtime needs to invoke managed code.ACW是一种JNI(java native interface)桥，这里的managed code指的是C#编译后的中间语言（IL）。ART运行的java代码通过ACW来调用C#代码在Mono中执行。 MCW：Managed Callable Wrappers are a JNI bridge which are used any time managed code needs to invoke Android code and provide support for overriding virtual methods and implementing Java interfaces。MCW也是一种JNI桥，为C#调用Android系统的API或者第三方写好的Java类库提供支持。 通过这两种方式，就可以让C#代码与Android平台的代码进行通信而且正常地运行了。 应用程序包Xamarin.Android开发出来的应用，结构上与普通的应用程序包差不多，比如res里的布局等，还多了以下的内容： 应用程序集（包含C#编译后的IL） Native libraries（对于不同架构机型的Mono运行时） 比如打包的HelloWorld.apk，解压后的目录：assemblies文件夹里就是应用程序集，包含了各种编译后的.dll文件lib文件夹里面就是native libraries。里面有个文件夹arm64-v8a和armeabi-v7a,里面都是分别对应处理器架构的Mono虚拟机（.so文件）。 其他的就跟普通的应用程序包差不多了，比如根目录的清单文件，res资源文件夹等。 总之一句话：The APK is still a valid Java APK. It Starts in ART,and uses ART for UI(Android.*classes). Mono is used to run .NET IL. The IL and Android native code run side-by-side and communicate via callable wrappers. (github的一条issue里面的，总结的很到位，~我翻译不了只能放英文了~)。 参考链接 官网文档 Xamarin.Android 运行原理 JNI原理 - 简书","categories":[{"name":".NET学习","slug":"NET学习","permalink":"https://yanghaku.github.io/categories/NET%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://yanghaku.github.io/tags/Android/"},{"name":".NET","slug":"NET","permalink":"https://yanghaku.github.io/tags/NET/"},{"name":"Xamarin","slug":"Xamarin","permalink":"https://yanghaku.github.io/tags/Xamarin/"}]},{"title":"Android入门知识","slug":"Android入门知识","date":"2020-01-31T03:19:00.000Z","updated":"2020-02-01T07:33:43.067Z","comments":true,"path":"2020/01/31/Android入门知识/","link":"","permalink":"https://yanghaku.github.io/2020/01/31/Android%E5%85%A5%E9%97%A8%E7%9F%A5%E8%AF%86/","excerpt":"想学习Android的第一步，就应该先了解这个平台系统的大体架构，应用的基础知识等，可是我看到很多入门教程第一步就是直接讲环境搭建下jdk什么的，这种太片面了，往后的NDK，安全沙盒什么的看了也很迷茫。所以我自己查找了许多资料并总结了一下。主要有：Android平台架构Android Application 基础知识 安全沙盒与最小权限原则 Android四大组件（重点） 组件启动与组件之间联系 应用的清单文件 应用资源Android SDK 目录结构及作用开发环境搭建","text":"想学习Android的第一步，就应该先了解这个平台系统的大体架构，应用的基础知识等，可是我看到很多入门教程第一步就是直接讲环境搭建下jdk什么的，这种太片面了，往后的NDK，安全沙盒什么的看了也很迷茫。所以我自己查找了许多资料并总结了一下。主要有：Android平台架构Android Application 基础知识 安全沙盒与最小权限原则 Android四大组件（重点） 组件启动与组件之间联系 应用的清单文件 应用资源Android SDK 目录结构及作用开发环境搭建 Android平台架构Android 是一个基于linux内核的开源软件栈，通过软件叠层的方式构建出来的一个操作系统。 平台的架构图（来自官网）： 从下到上分为五层： Linux内核层，HAL硬件抽象层，Library层，Framework层，Application应用层。 Linux内核层Android平台的基础是Linux内核，主要用linux内核执行一些底层的功能，比如线程和底层的内存管理，还有各种设备的驱动，直接和硬件打交道。linux内核的安全性也能保证这Android的安全。 HAL硬件抽象层HAL提供了一个标准的界面，向更高级别的javaAPI框架显示设备的硬件功能。每一个硬件组件都是对应着一个库模块，比如相机模块，蓝牙模块，音频模块等。当javaAPI框架需要访问硬件的时候，Android会为这些硬件加载对应的库模块。其实就是对底层硬件驱动的一种封装，让javaAPI框架层只看到一个标准的接口，而有了硬件的无关性。 Libarary层系统的运行库层，这层主要提供了一些必不可少的运行库。 Android RuntimeAndroid Runtime 包括两部分，一部分是核心运行时库，为javaAPI框架提供java语言中的大部分功能；另一部分是Android运行时。 在Android 5.0 之前，Android运行时都是Dalvik虚拟机。Dalvik虚拟机相当于一个适配于移动设备更优化的一个java虚拟机（JVM）,也是用JIT编译器来解释运行字节码。Dalvik运行的是.dex格式的字节码，是构建的时候将.java源码编译成 .class字节码，然后再压缩优化成.dex的字节码。 这个Dalvik可以与java虚拟机对比理解首先就是Dalvik本身就是一个魔改的java虚拟机，是一种基于寄存器的架构，虽然牺牲了一些平台无关性，但是在代码运行效率方面都比jvm更胜一筹。JVM与Dalvik区别： 运行的字节码不同，指令集架构不同，JVM基于栈，Dalvik基于寄存器 JVM只运行一个实例，所有的应用都运行在同一个虚拟机中，而Dalvik是每一个应用启动都有一个单独的Dalvik虚拟机对应，每一个Dalvik都对应linux里的一个进程。这样就算其中一个应用crash掉了，也不会影响其他的应用。 到了Android 5.0版本之后，这一部分就变成了Android Runtime（ART），ART与Dalvik相比，增加了更多的功能： 不仅有JIT，而且还增加了AOT（预先编译） 优化垃圾回收 更好的调试支持 预先编译是在安装的时候将 .dex 文件编译成机器码（所以安装的时间会变慢很多），运行的时候跳过了解释的阶段，运行效率之类的都显著提高，但是占用的存储空间就大了，也就相当于用空间来换时间。这样使CPU的利用率也降低不少，能够提升电池的续航时间。 总之，Android Runtime安卓运行时就是用来运行apk里的.dex代码的。一个APP对应一个ART实例，并且对应于一个进程。 Native C/C++ Libarary原生C/C++库，通过一些c/c++库为安卓系统提供了一些主要的特性支持。比如OpenGL库提供3D绘图，SQLite库提供数据库支持，WebKit库提供浏览器内核支持…. 这些主要是一些关键的东西（效率至上），所以是用C/C++的库来提供支持。 应用不仅可以调用javaAPI层来访问这里面的模块，而且可以直接调用这些原生库的功能（一般都是在c/c++原生开发的时候）。 NDK: native develop kit 原生开发工具包当c/c++ 原生开发的时候用到的工具包，其实对大部分的应用都没有很大的价值，因为这不可避免地增加了开发的复杂度。一般在以下场景才会用到： 为了非常好的性能。例如游戏，物理模拟这些计算密集型的应用 重复使用自己或者其他开发者已经开发好的c/c++库 在平台之间移植应用 JAVA API Frameworkjava API框架，这层主要是用java写的API，包含了Android OS的整个功能集（也就是说开发的时候可以调用这里面的API就可以实现所有功能）。里面包括着各种系统的服务和四大组件（后面会介绍到）。 System Application 和 Application系统应用可以说是系统内置的应用，这些对于开发者而言，可以像调用java API Framework一样来调用这些System Application。Application就是我们自己写的第三方的应用这种了，是在最上层。 总之，Android APP的开发语言最好还是官方的JAVA/Kotlin，如果有特殊的需要才会用到native c/c++.对于应用开发人员主要研究的就是架构里面的Java API Framework层和System Application层。如果有需要还会用到native c/c++ Library。就像Android运行时和运行库和下层的驱动等，不是研究的重点，在把握全局的同时，也要搞清楚重点。 Android Application 基础知识一个APK文件，包含一个Android应用的所有内容。使用Kotlin，Java，c++编写Android应用，Android SDK会将代码连同数据和资源文件编译成一个APK（Android Package），即带有.apk后缀的归档文件。 安全沙盒与最小权限原则安全沙盒 security sandbox 沙箱(盒)是为执行中的程序提供隔离环境的一种安全机制。它通过严格控制执行的程序锁访问的资源，以确保系统的安全。每一个Android应用都处于各自的安全沙盒里面，它们直接不能互相访问文件等。 Android操作系统首先是多用户的Linux系统，对于每一个应用都是一个不同的用户。 默认情况下，系统会为每一个应用分配一个唯一的用户ID，系统为应用中的所有文件设置权限，使得有权限的用户才能访问对应的文件。 每个进程都拥有一个独立的虚拟机，默认情况下，每个应用都在其自己对应的Linux进程上执行（应用-虚拟机-Linux进程 这三个是一对一的关系） 最小权限原则对于每一个应用，也就是对应的一个唯一的Linux用户，默认情况下只能访问其工作所需要的组件。在此环境中，应用无法访问其未获得权限的系统部分。应用要想访问其他应用的共享数据或者系统服务，有两个途径： 让两个应用共享一个Linux用户（也就是说两个应用的linux userid相同），这样二者可以互相访问。在节省资源的时候，也可以安排拥有相同用户ID的应用在同一个Linux进程内运行，共享同一个虚拟机。 应用可以请求访问设备数据的权限，由用户明确授予这些权限。比如说应用请求获得访问文件，访问相机，访问联系人等等的权限，由用户明确授予即可。 Android四大组件（重点）应用的四大组件： Activity： 拥有用户界面的单一屏幕 Service：在后台运行的组件，没有界面 BroadcastReceiver： （广播接收器）相应系统的广播通知的组件 Content providers：（内容提供程序），管理共享数据，为其他应用提供查询修改接口 ActivityActivity是与用户交互的入口点，拥有单个的屏幕。 官网上的举例：例如电子邮件的应用可能会有三个Activity： 显示新电子邮件列表的Activity 用于撰写电子邮件的Activity 用于阅读电子邮件的Activity这三个紧密协作联系，但是每个Activity都是独立于其他的Activity而存在，其他应用可以启动其中任何一个Activity。 这很像一个web中的一个网页，每一个网页都是独立的，它们一起构成一个网站，其他别的链接也可以打开这个网站里的任何一个网页（当然在Android里面就还会涉及到权限能不能打开的问题）。然后同一时间只能有一个网页显示在屏幕上（独占一个屏幕）。 Activity的生命周期首先是一个标准的图： Activity 包括7个生命周期的流程，分别是： 1onCreate(),onStart(),onResume(),onPause(),onStop(),onDestory(),onRestart(). 其中 onCreate()是生命周期的开始，onDestory()是生命周期的结束 Activity启动： onCreate() -&gt; onStart()（此时不可见） -&gt; onResume -&gt; 处于运行态，可见 Activity被暂时覆盖：onPause() , 当用户取消覆盖的时候 onResume() 恢复 Activity跳转到了新的Activity、Activity进入了后台或者锁屏的时候：running的Activity -&gt; onPause() -&gt; onStop() -&gt; 停滞状态的Activity Activity重新回到前台或者解锁的时候： 停滞状态的Activity -&gt; onRestart() -&gt; onStart() -&gt; onResume() -&gt; Activity重新running Activity在后台且内存不足的时候：系统会杀死这个后台状态的Activity（此时这个Activity的引用虽然在任务栈中，但是这个时候引用指向的对象已经是null）。若想再回到running，就需要重新初始化生命周期: onCreate() -&gt; onStart() -&gt; onResume() Activity退出: onPause() -&gt; onStop() -&gt; onDestory() (上面的方法都是对应事件的回调函数，选择重写的方法而不能主动调用。如果想主动退出Activity，应该调用finish())。 Activity的四种启动模式因为我们的APP一般都是由多个Activity构成的，而在Android给我们提供了任务（Task）的概念，就是将多个相关的Activity收集起来，进行Activity的跳转与返回。实现Android就是通过任务栈来管理这些Activity的。任务栈：任务栈是一种后进先出的结构。切换到新的Activity，就会被压入栈中成为栈顶。位于栈顶的Activity处于running状态。当back按钮按下的时候，栈顶的Activity会出栈并且调用onDestory()结束生命周期，紧随其后Activity的成为栈顶。当栈内没有Activity那么系统就会回收这个栈，每个APP默认只有一个栈，以这个APP的包名来命名。 四种启动模式： standard标准模式: 默认的模式，新的Activity会默认压入栈中。 singleTop栈顶复用模式：如果新的Activity在任务栈的栈顶（也就是跟栈顶的相同）那么就不会重新创建。如果不在任务栈的栈顶，就跟standard模式相同。 singleTask栈内复用模式：如果新的Activity在任务栈的栈内，那么新的Activity就不会创建，而是将原本栈内的Activity调到栈顶（这个Activity之上的所以Activity都会被清理销毁）。 singleInstance单例模式：这个要求更严格，这种模式的Activity只能单独的位于一个任务栈里面，是一个加强版的singleTask。任务栈里面只能有这一个Activity。 Service服务是Android中实现程序后台运行的解决方案，非常适合去执行那些不需要和用户交互而且还要求长时间运行的任务（没有界面）。比如下载，播放音乐等等。 Service的生命周期先看图：首先service的声明中，onCreate()只会回调一次来创建,onDestory()只会在关闭的方法回调一次。启动service的方法有三种： StartService()启动service BindService() 启动service start之后再bind 这几者的区别：StartService只是启动这个service，启动它的组件（比如Activity）和这个Service没有关联。service的关闭只能是自己执行完某些任务了之后执行stopSelf或者其他组件调用它的stopService才能终止。BindService方法启动的Service，其他组件可以通过回调获取Service的代理对象和Service交互，而且两方进行绑定，当启动的组件销毁的时候，Service会自动进行unBind操作解绑。当发现所有的绑定都进行了unBind的时候，Service会销毁。先start然后另一个组件进行bind这个已经启动的Service的时候，系统仅仅是进行了绑定而不会把生命周期与另一个组件绑定。也就是解绑了之后Service还是属于start启动的service。 BroadcastReceiver广播能够广泛的运用在应用程序之间传递事件信息的机制。借助广播接收器，系统能够在常规的用户流之外向应用传递事件，从而允许应用响应系统范围内的广播通知。广播接收器可以对许多外部事件进行响应，比如当电话呼入，手机屏幕关闭等事件，系统会发出广播，对应的注册的广播接收器会收到这些事件消息对应地处理。广播接收器虽然没有界面，但是可以创造状态栏的通知。比如wifi连接-&gt; 系统广播事件-&gt;对应的广播接收器收到后创建通知：网络连接恢复。 广播接收器有两种注册方法：静态注册和动态注册 静态注册： 在AndroidManifest.xml（应用清单文件，下文会仔细解释）里声明，当APP首次启动的时候就注册到系统中。 动态注册： 在某个组件（一般是Activity）运行的时候注册广播接收器。区别：静态注册是一直在监听对应的消息，耗电耗内存，当APP退出之后也能收到对应的消息进行处理。 动态注册是在代码中动态的注册，当组件退出之后也没法接受广播了（注意要在组件结束前移除广播接收器，否则会导致内存泄漏）。 Content providers内容提供者提供内容的共享。可以将文件，数据库，网络上的可持久化的数据提供给其他应用修改查询。一般有两个场景： 自己的应用需要访问别的应用的数据，比如访问手机联系人，短信等，想对这些数据进行读取或修改，就要用到这些应用的ContentProvider。 自己的应用需要给别的应用共享信息，也要用到ContentProvider，而且可以选择性的共享信息，避免了关键隐私信息泄露等。 组件启动与组件之间联系Android系统的独特之处在于，任何应用都可以启动其他应用的组件。 比如一个应用想让用户使用设备相机拍摄照片，那可以使用系统的照片应用中对应的Activity即可，当拍摄之后会返回到原先的应用，对用户来说这相机就如同应用的一部分。当系统启动一个应用的组件时候，就会启动这个应用对应的进程（如果没有启动的话）。这个应用和相机还是属于两个进程。所以说Android应用没有单个的入口点（main()函数），每一个组件都可以是应用的入口。 因为安全沙箱的存在，不能直接启动另一个应用的组件，而是需要系统作为中间人。这些组件之间启动或者访问，就需要传递消息，这个消息就是 Intent（意图）。 Intent 是启动组件，是组件直接联系的桥梁。四种组件之中，Activity，Service，BroadCastReceiver 这三个组件都是通过Intent启动。（ContentProvider会在ContentResolver请求目标的时候启动，与其他不一样）。对于启动Activity和Service，Intent会定义要执行的操作，并且可以指定待操作的数据等信息。对于BroadcastReceiver，Intent只会定义待广播的通知。 Intent对象大致包括7个属性：Action（动作），Data（数据），Category（类别），Type（数据类型），Component（组件），Extra（扩展信息），Flag（标志位）。 Intent分为显式Intent和隐式Intent。 显式Intent： 直接通过组件名来启动某个组件，每次启动的组件只有一个。 隐式Intent： 不指定组件名，而是指定Intent的Action，Data等（只描述意图），当我们启动的时候，会匹配出相关的满足要求的组件，如果不止一个，就会让用户选择使用哪个来处理Intent。一个最熟悉的场景就是隐式Intent： 应用的清单文件在Android系统启动应用之前，系统必须通过读取应用的清单文件（AndroidMainifest.xml）确认组件的存在，应用中所有用到的组件(除了动态注册的广播接收器) 都需要在这个文件中声明。这个文件必须位于应用目录的根目录中。除了声明应用的组件之外，清单文件还有许多其他的作用，比如： 确定应用需要的任何用户权限，比如访问联系人，访问文件等 根据应用使用的API，声明所需的最低API级别 声明需要的硬件软件功能，比如相机等 主要的三个功能： 声明组件代码里的Activity就是声明的一个组件 123456789&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;manifest ... &gt; &lt;application android:icon=\"@drawable/app_icon.png\" ... &gt; &lt;activity android:name=\"com.example.project.ExampleActivity\" android:label=\"@string/example_label\" ... &gt; &lt;/activity&gt; ... &lt;/application&gt;&lt;/manifest&gt; 声明组件的功能这个就是声明了一个执行动作为SEND发送的一个组件 123456789101112&lt;manifest ... &gt; ... &lt;application ... &gt; &lt;activity android:name=\"com.example.project.ComposeEmailActivity\"&gt; &lt;intent-filter&gt; &lt;action android:name=\"android.intent.action.SEND\" /&gt; &lt;data android:type=\"*/*\" /&gt; &lt;category android:name=\"android.intent.category.DEFAULT\" /&gt; &lt;/intent-filter&gt; &lt;/activity&gt; &lt;/application&gt;&lt;/manifest&gt; 声明应用要求123456&lt;manifest ... &gt; &lt;uses-feature android:name=\"android.hardware.camera.any\" android:required=\"true\" /&gt; &lt;uses-sdk android:minSdkVersion=\"7\" android:targetSdkVersion=\"19\" /&gt; ...&lt;/manifest&gt; 应用资源Android应用不仅仅是代码，还需要与源代码分离的静态资源，比如图像，音频文件还有xml文件定义的界面动画等。所有的资源都在 /res 的文件夹内。 Android SDK 目录结构及作用1234567891011121314android-sdk&#x2F; add-ones&#x2F; -&gt; 一些附加的库，第三方公司的附加功能，比如GoogleMaps等 build-tools&#x2F; -&gt; 构建项目的时候用到的工具，还包括一些编译工具等 28.0.3&#x2F; 29.0.3&#x2F; docs&#x2F; -&gt; 离线的开发者文档（可选） platforms&#x2F; -&gt; sdk里面最重要的文件，每个文件夹都含有各个版本的sdk android-28&#x2F; -&gt; API级别28的sdk版本 android-29&#x2F; platforms-tool&#x2F; -&gt; 各版本sdk通用的工具，比如abd.exe,sqlite3.exe等 skins&#x2F; -&gt; 安卓模拟器的皮肤 system-images&#x2F; -&gt; 创建安卓模拟器的时候使用的系统镜像 android-28&#x2F; tools&#x2F; -&gt; 通用的Android开发、调试的工具 还有两个很重要的工具： SDK管理器 和 安卓模拟器管理器。（可以直接用IDE上带的工具来代替） 开发环境搭建操作系统：win10IDE：Android Studio （用起来跟idea一个感觉，非常棒！~比VS强太多了~）（直接官网下载安装即可） 安装之后主要是设置SDK和模拟器。（我之前用VS下过一个sdk，Android Studio直接识别出来本地的了！） 设置好之后就新建工程，然后新建一个空白的工程，一路next，IDE会自动生成一个空白项目。项目结构如下： 根目录里的清单文件 AndroidMainifest.xmljava/ 下的java代码（只有一个组件MainActivity）res/ 里是应用的各种资源，包括布局，图片等等。res/layout 里的activity_main.xml 就是MainActivity这个Activity对应的布局文件。 配置好模拟器设备之后，直接点击run运行即可完成 Hello World! 参考链接 Android开发者平台（官网有最新文档） Android基础入门教程-菜鸟教程 简单理解Android Dalvik Android Runtime (ART) 和 Dalvik NDK开发从放弃到入门 安卓基础知识-简书 安卓四大组件-简书 Android四大组件：BroadcastReceiver史上最全面解析-简书","categories":[{"name":"Android学习","slug":"Android学习","permalink":"https://yanghaku.github.io/categories/Android%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://yanghaku.github.io/tags/Android/"}]},{"title":"Xamarin学习1 -- 概念篇","slug":"Xamarin学习1概念篇","date":"2020-01-30T08:46:00.000Z","updated":"2020-02-01T08:32:05.914Z","comments":true,"path":"2020/01/30/Xamarin学习1概念篇/","link":"","permalink":"https://yanghaku.github.io/2020/01/30/Xamarin%E5%AD%A6%E4%B9%A01%E6%A6%82%E5%BF%B5%E7%AF%87/","excerpt":"主要介绍了 Xamarin 中 Xamarin.forms , Xamarin.Android, Xamarin.iOS 的区别和联系，并且搭建环境和创建第一个 Xamarin.forms 应用并运行调试。","text":"主要介绍了 Xamarin 中 Xamarin.forms , Xamarin.Android, Xamarin.iOS 的区别和联系，并且搭建环境和创建第一个 Xamarin.forms 应用并运行调试。 XamarinXamarin是Mono开源项目的一个分支，把Mono里移动开发这一块专门拿出来做成了一个商业项目。（原先是收费的商业项目，到了2016年微软把Xamarin公司收购了，才变成开源的了。）现在Xamarin是一个开源平台，用于通过 .NET 构建适用于 IOS，Android 和 Windows 的新式应用程序。是一个抽象层，可用于管理共享代码与基础平台代码的通信。使开发人员能够跨平台共享应用程序，允许开发人员以一种语言编写所有的业务逻辑，但是在每个平台上各自实现外观等。 说白了就是共享底层逻辑的 C# 的代码，并且创建各自的UI, 使得一个工程开发能够多个平台使用。 然后就是 Xamarin 的结构： Xamarin.AndroidXamarin.Android 是将 C# 编译为中间语言，然后在程序运行的时候，通过即时编译（JIT）编译成本机程序集（类似于java虚拟机的那种）。 Xamarin.iOSXamarin.iOS 是将应用程序完全编译成本机的ARM程序集代码（完全的静态编译）。 Xamarin.Android 和 Xamarin.iOS 其实就是两个单独的工程，前者是专门对于Android开发的，后者是专门对于iOS开发的工程。但是Xamarin不是跨平台的吗？ 这个时候就用到了 Xamarin.Forms 了！ Xamarin.FormsXamarin.Forms 是一个开源的 UI 框架，允许开发者写一种UI布局与设计，然后根据不同的平台渲染成不同的UI控件(实现了跨平台的UI开发) 上图中的 Xamarin.Forms Platform Renderer 就是做这种事情的。 就像官网文档说的： Who Xamarin.Forms is forXamarin.Forms is for developers with the following goals: Share UI layout and design across platforms. Share code, test and business logic across platforms. Write cross-platform apps in C# with Visual Studio. UI的开发可以是原生开发，也可以是用Xamarin.Forms开发，原生开发就是使用Android和iOS原生的UI控件。基于Xamarin.Forms的UI开发可以使代码共享程度进一步提高：从上图可以看到，左边的原生UI开发，代码共享程度是75%左右，也就是说只是共享了后台的逻辑代码了，前端的UI还是要各自做各自的。右边的Xamarin.Forms开发的项目，代码共享程度到了95%，这就几乎没有多少平台相关的代码了。 以上的关系总结 Xamarin.Android 和 Xamarin.iOS (其实还有Xamarin.Mac , Xamarin.UWP，Xamarin.tvOS 等) 这些都是Xamarin里的具体的工程， 专门对应于具体的平台里的，可以单独开发。 而Xamarin.Forms 是用于跨平台的，可以实现同时开发Android和iOS和UWP 等，将一个共享的UI框架分别渲染到具体的平台工程里去，实现大部分的UI和逻辑代码共享。 比如在VS2019 里面创建一个Xamarin项目的时候，可以看到非常多的选项： 第一个Xamarin.Forms 就是一个跨平台的方案，当在Xamarin forms创建的时候勾选这Android和iOS的时候(因为没有装UWP的开发环境，所以只选了这两个)，项目的结构就会如下： 也就是说， Xamarin.Forms 包含了其他的工程，而像 Xamarin.Android 这种既可以是独立开发的工程，也可以当做Xamarin.Forms 里的一部分通过Xamarin.Forms 一起开发。 所以说清楚了这些之后，官网上的那些文档也就不觉得混乱了， 想学哪一块就可以针对性地学习了。 环境搭建操作系统 ： win10 IDE： visual Studio 2019 （刚下载的） 如果只需要Android和iOS开发的话，只要在vs installer 上选择移动开发的负载下载即可 安卓需要java SDK 8， Android SDK 和安卓模拟器 这三个东西vs都给自动装好了. 其中jdk8自动被安装才了“C:\\Program Files\\Android\\jdk\\microsoft_dist_openjdk_1.8.0.25”. Android SDK 装在了 “C:\\Program Files (x86)\\Android\\android-sdk” （当然，可以自己设置） 然后安卓的模拟器就是自动保存在了自己用户文件夹下的 “.Android” 里面（这个需要自己安装设备，具体在下文） 安卓模拟器有硬件加速，运行之前需要在 “控制面板”-&gt; “程序与功能” -&gt; 左栏 “启用或关闭windows功能” -&gt; “windows虚拟机程序监控平台” 勾选上， 否则每次运行之前都会有一个警告。 第一个 Xamarin.Forms 工程打开vs， 新建项目，在框里搜索 Xamarin， 点击选中 Xamarin.forms, 然后设置项目名称，目录等， 然后点创建。 之后选择空白的模版， 平台勾选Android和iOS （有环境的也可以勾选UWP试试），然后就创建完成。 项目结构： 其中XamarinApp1.Android 就是对应的生成安卓的工程， XamarinApp1.iOS 就是对应的iOS的工程。 在MainPage.xaml 中编辑，把 “Welcome …” 换成 “hello World” （程序猿开发第一步嘛），然后就是运行了。 Xamarin.Android 的运行调试运行安卓之前需要安装安卓的模拟器，VS的安卓工具里有两个挺重要的工具：Android SDK管理器和 Android 设备管理器。 点击工具 -&gt; Android -&gt; Android SDK 管理器 我这上面是下载的默认的 安卓SDK9; 设置的图片： Android SDK 有了之后，就安装对应的设备就行了。点击 工具 -&gt; Android -&gt; Android Device Manager 点击新建（新建一个安卓虚拟设备） 操作系统要选择已经装好的sdk对应的版本， 处理器选择 x86（官网说x86比x86_64实际会快，而且可以硬件加速） ，其他可以不用多设置（以后可以再改嘛，先能运行再说）， 点击创建即可。 创建完成后，在上面的工具栏里，选择需要运行的Android和对应的设备，点击运行，即可完成 运行截图： 到此第一步完成，Android上部署成功！ Xamarin.iOS 运行调试Xamarin.iOS 调试需要iOS真机， 如果是模拟器也需要MAC系统才行（贫穷限制了开发人员的学习）。 找了一圈，发现了一个方案： windows装 MAC虚拟机，然后再MAC上装模拟器和VS，详情 可以实现但是太麻烦，就不瞎折腾了。 这个跨平台是挺棒，但是不代表着学习了Xamarin就会了Android和iOS的开发， 每个平台的特性都需要了解的。iOS 系统的很多特性都不了解是写不出来高质量的程序的，甚至还得要求开发者掌握一些 Object-C 的语法 。所以说没有接触使用过iOS的我果断放弃啦.. 所以对于我个人来说，往后的学习可能只是限制在Xamarin.Android， 而不是上面的跨平台特性（没有其他平台的需求）。 如果只学习 Android开发，用java入门更好，但是多学点新的东西不也很刺激么hh 以上仅仅是我个人的理解，不一定是完全正确的！！ 如果有错误请评论指出，谢谢！ 参考链接 官网Xamarin文档 Xamarin.Form与Xamarin.Android或Xamarin.IOS的区别简述 写给 iOS 程序员的 Xamarin 入门教程 Xamarin介绍","categories":[{"name":".NET学习","slug":"NET学习","permalink":"https://yanghaku.github.io/categories/NET%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://yanghaku.github.io/tags/Android/"},{"name":".NET","slug":"NET","permalink":"https://yanghaku.github.io/tags/NET/"},{"name":"Xamarin","slug":"Xamarin","permalink":"https://yanghaku.github.io/tags/Xamarin/"},{"name":"iOS","slug":"iOS","permalink":"https://yanghaku.github.io/tags/iOS/"}]},{"title":".NET初学概览","slug":"NET概览","date":"2020-01-29T08:46:00.000Z","updated":"2020-02-25T09:39:00.828Z","comments":true,"path":"2020/01/29/NET概览/","link":"","permalink":"https://yanghaku.github.io/2020/01/29/NET%E6%A6%82%E8%A7%88/","excerpt":"主要是对 .NET Core, .NET Standard, .NET framework 和 Xamarin 的介绍和区分 并且介绍一下其中的ASP.NET, UWP， XAMARIN 等 然后就是 .NET 的未来： .NET 5 （2019年5月宣布的下一代的版本），将把前面这些运行时全部合为一体 以前刚开始听说 .NET 的时候，我只知道 .NET framework , 然后昨天看了一眼官网的 .NET 入门学习的时候吗，又看到了 .NET Core, 然后各种名词接踵而来，有点懵，所以就总结了一下下。","text":"主要是对 .NET Core, .NET Standard, .NET framework 和 Xamarin 的介绍和区分 并且介绍一下其中的ASP.NET, UWP， XAMARIN 等 然后就是 .NET 的未来： .NET 5 （2019年5月宣布的下一代的版本），将把前面这些运行时全部合为一体 以前刚开始听说 .NET 的时候，我只知道 .NET framework , 然后昨天看了一眼官网的 .NET 入门学习的时候吗，又看到了 .NET Core, 然后各种名词接踵而来，有点懵，所以就总结了一下下。 首先就是当下的框架图： .NET广义的 .NET 是一个通用的开发平台，能够跨语言，跨平台 ，能够支持跨多个平台的方案 .NET 开发可以实现包括 .NET Framework、.NET Core 和 Mono。 .NET 的所有实现都有一个名为 .NET Standard 的通用 API 规范。 .NET 与 java 对比理解： .NET 与 java有很多相似的地方，两者都是即时编译语言（JIT）， 项目编译生成的文件不是具体的机器码，而是中间语言。 在java里面叫做字节码（bytecode）， 而在 .NET里面叫做中间语言（Common Intermediate Language，简称 IL），java官方运行环境是java的虚拟机JRE（Java Runtime Environment）， 而在 .NET 官方运行环境叫做公共语言运行时（Common Language Runtime， 简称CLR） 这是 .NET 跨语言，跨平台的基础 跨语言： c#， f#， VB.NET 这些面向 .NET 的都可以 跨平台： 开发 Windows，Linux，macOS，iOS，Android，tvOS，watchOS 和 WebAssembly .NET framework传统的 .NET framework 是以一种采用CLR 为基础，支持多种语言（c#，f#，VB.NET, c++，Python等）的开发。 这也是我们用到的最多最熟悉的 .NET , 这个缺点就是不能跨平台，只能在windows上用。一般就是用来做桌面应用程序和ASP.NET的. .NET Core主要是针对windows，linux，macOS，服务器和控制台应用程序的跨平台 .NET 实现 它支持四种应用程序：控制台，ASP.NET Core, 云 和通用windows平台( UWP ) 需要注意的是: 尽管微软把 .NET Core作为.NET未来的发展方向，但 .NET Core和 .NET Framework 仍然是两个独立的产品。.NET Framework也会继续更新和维护。 .NET Core 不再是windows 专门的，在其他平台也可以用。 就是为了跨平台而做的，不是windows的一个组件了。 .NET Standard.NET Standard 是一组由.NET 实现的基本的API集。 是一个进一步实现跨平台跨设备的代码共享。其实是未来 .NET的核心，一切基于它来实现代码共享。 .NET Standard 和 .NET 之间 相当于html 规范和 浏览器之间的关系，后者是前者的实现。 Xamarin 与 MonoMono是 .NET 开源之前的一个跨平台的方案，是由Xamarin公司主持的开源项目，可以运行于Linux等其他平台 （于2016年被微软收购）。相当于实现了各个平台上的 .NET 的公共语言运行时（CLR）。 现在主要运用在移动设备，许多著名的游戏引擎比如Unity3D也包含着这个技术。 对于IOS和Android 应用程序，Xamarin 将 .NET 技术代入里面， 成为唯一一个能够提供跨iOS，Android和windowsPhone 的单一语言平台。 ASP.NET 和 ASP.NET Core这两个只是以上框架里的一个小组件，用于开发Web应用程序。 然后两个的区别就是ASP.NET 是 .NET framework 里的组件， 只有windows版本的API 而ASP.NET Core 是 .NET Core 的组件，是对于跨平台准备的，是 ASP.NET 的跨平台版本。 所以说以上这么多的名词，都是因为不断进化产生的，从只有一个 .NET framework 只支持windows平台，到后来的跨平台的方案，都在慢慢发展来的。 三个框架与应用总结所以再回顾一下上面的那个图片: 现在主要的三个框架实现 .NET Framework （最新到4.8版本）主要是对windows平台的 .NET Core （最新到3.1版本）可以跨平台，主要是一些控制台设备，如linux，windows，macOS等 XAMARIN 主要是针对移动设备的，比如Android，iOS等 官网文档上说的： There are various implementations of .NET. Each implementation allows .NET code to execute in different places—Linux, macOS, Windows, iOS, Android, and many more. .NET Framework is the original implementation of .NET. It supports running websites, services, desktop apps, and more on Windows. .NET Core is a cross-platform implementation for running websites, services, and console apps on Windows, Linux, and macOS. .NET Core is open source on GitHub. Xamarin/Mono is a .NET implementation for running apps on all the major mobile operating systems, including iOS and Android. .NET Standard is a formal specification of the APIs that are common across .NET implementations. This allows the same code and libraries to run on different implementations. .NET 5 未来的展望现在这么多的框架什么的，到了 .NET5 将会融为一体。 .NET 5 将会融合 .NET Framework , .NET Core, Mono, Xamarin 等优点构建出一个统一的 .NET 平台，开发人员可以使用 C#， VB.NET, F# 等语言，使用相同的API 开发针对任何系统，任何架构，任何形态的应用程序，并且代码和库均可通过 .NET Standard 共享 。 也就是说，到了那个时候开发出一个应用程序，就可以全平台通吃，只要有一个 .NET, 就能一次开发出适用于Windows，Linux，macOS，iOS，Android，tvOS，watchOS 和 WebAssembly 等所有平台的应用程序了。 希望早日到来，让俺们这些开发人员感受感受叭。 2019年5月微软宣布的.NET5， 将会在 2020年11月发布 参考链接： .NET:持续进化的统一开发平台 .NET Core和.NET Standard有什么不同 (翻译)正式宣布 .NET 5","categories":[{"name":".NET学习","slug":"NET学习","permalink":"https://yanghaku.github.io/categories/NET%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":".NET","slug":"NET","permalink":"https://yanghaku.github.io/tags/NET/"},{"name":".NET Core","slug":"NET-Core","permalink":"https://yanghaku.github.io/tags/NET-Core/"},{"name":".NET Framework","slug":"NET-Framework","permalink":"https://yanghaku.github.io/tags/NET-Framework/"},{"name":"Xamarin","slug":"Xamarin","permalink":"https://yanghaku.github.io/tags/Xamarin/"}]},{"title":"失踪半年人口回归","slug":"失踪半年人口回归","date":"2020-01-29T03:00:00.000Z","updated":"2020-01-29T13:29:00.195Z","comments":true,"path":"2020/01/29/失踪半年人口回归/","link":"","permalink":"https://yanghaku.github.io/2020/01/29/%E5%A4%B1%E8%B8%AA%E5%8D%8A%E5%B9%B4%E4%BA%BA%E5%8F%A3%E5%9B%9E%E5%BD%92/","excerpt":"今天是大年初五，2010.1.29， 在家连续玩了四天了，要开始继续学习了呀。 自从电脑从linux 换成 windows ，就没有再重新配置hexo的环境（说白了太懒了），昨天折腾了一整天，把电脑里的文件整理、清理，升级或者卸载不用的软件，外加更新几个linux的虚拟机，整整折腾了一整天。昨天又下了nodejs，重新搞了一下hexo，继续写吧，每天学学学，总得留下什么吧。 还是没有养成写点东西的习惯，许多东西学得快，忘得也快。还有一些算法或者什么思想啦，只在脑中形成一些概念而已，没有经过系统的思考，慢慢也会忘掉的。记笔记尤其是写markdown，总能梳理出一个清晰的思路来。就比如过年之前花费了十几天","text":"今天是大年初五，2010.1.29， 在家连续玩了四天了，要开始继续学习了呀。 自从电脑从linux 换成 windows ，就没有再重新配置hexo的环境（说白了太懒了），昨天折腾了一整天，把电脑里的文件整理、清理，升级或者卸载不用的软件，外加更新几个linux的虚拟机，整整折腾了一整天。昨天又下了nodejs，重新搞了一下hexo，继续写吧，每天学学学，总得留下什么吧。 还是没有养成写点东西的习惯，许多东西学得快，忘得也快。还有一些算法或者什么思想啦，只在脑中形成一些概念而已，没有经过系统的思考，慢慢也会忘掉的。记笔记尤其是写markdown，总能梳理出一个清晰的思路来。就比如过年之前花费了十几天学习了java的SSM框架，虽然学了写了好多，但是现在就感觉全部忘掉了····· 也许是记忆力也出了点小问题叭。不管怎样，我还是要记下来，每天都记一记。 首先还是要好好反思自己，作为一名现役的ACM队员，19年下半年做的题量还不如我大一的一个月做的多，这是非常不正常的，银川回来之后，原想努把力去上海冲个金，结果才拿了铜，ccpc-final和ec-final相继打铁。想想也是太丢人了，我的状态不对呀！ 及时改变自己吧，生活还是可以回到正轨上来的。下个赛季，大四再打一个赛季，把在赛场上丢的脸捡回来，证明自己。 确实不应该，放弃了最好的一个学期去做了自己都知道没有结果的事情。冷静下来一想，是自己没有把握好度，失去了理智像飞蛾扑火般，不管怎样，都是一段很好的回忆叭。 自己也是在不断成长的呢，明白了许多的道理，看到了自己以前没有看到的方面，知道了自己的不足，也算是一种提高，一种阅历吧。 总之，悟已往之不谏，知来者之可追！！ 1000题的小目标还没开始做呢，不要老想着明天啦，明日复明日，明日何其多嘛，现在就开始！ 我的数论模版还没整理完呢，希望能在开学前整理完~~ java的SSM框架的工程才写了一半，希望也能抽空写完~~（idea intellij 太好用了，吹爆！jb-mono字体也很棒哦） 昨天晚上突然看了一眼 .net , 学着用c#写了一个hello world，感觉还挺有意思，希望能有空学一学~~ 当然 linux内核的源码也想学学，这本书放桌面上几个月了还没看…… 还是挺多东西学习的，继续加油叭，奥利给！！ 奥利给！！","categories":[{"name":"日常碎碎念","slug":"日常碎碎念","permalink":"https://yanghaku.github.io/categories/%E6%97%A5%E5%B8%B8%E7%A2%8E%E7%A2%8E%E5%BF%B5/"}],"tags":[],"author":"yb"},{"title":"2019东北地区四省赛","slug":"2019东北地区四省赛","date":"2019-05-22T06:00:00.000Z","updated":"2019-06-04T13:31:37.000Z","comments":true,"path":"2019/05/22/2019东北地区四省赛/","link":"","permalink":"https://yanghaku.github.io/2019/05/22/2019%E4%B8%9C%E5%8C%97%E5%9C%B0%E5%8C%BA%E5%9B%9B%E7%9C%81%E8%B5%9B/","excerpt":"题目pdf链接 提交链接(codeforces)","text":"题目pdf链接 提交链接(codeforces) 在现场(我)写崩了C题，虽然最后救回来了（队友带飞），但是还差一点，差一题才到金 概览： A. Apple Business B. Balanced Diet C. Line-line Intersection D. Master of Data Structure E. Minimum Spanning Tree F. Mini-game Before Contest G. Radar Scanner H. Skyscraper I. Temperature Survey J. Time Limit A. Apple Business pending（暂时不会） B. Balanced Diet题意：给你n个糖果，每个糖果有价值$a_i$,属于种类$b_i$,让选择一些糖果，使得 (总价值/选择种类最大的个数) 尽量大，第j种糖果如果选择，选择的个数就应该大于等于$l_j$,(1","categories":[{"name":"现场赛の补题","slug":"现场赛の补题","permalink":"https://yanghaku.github.io/categories/%E7%8E%B0%E5%9C%BA%E8%B5%9B%E3%81%AE%E8%A1%A5%E9%A2%98/"}],"tags":[{"name":"codeforces","slug":"codeforces","permalink":"https://yanghaku.github.io/tags/codeforces/"}],"author":"yb"},{"title":"2018-2019 ICPC, NEERC, Southern Subregional Contest ","slug":"2018-2019-ICPC-NEERC-Southern-Subregional-Contest","date":"2019-05-20T00:54:00.000Z","updated":"2020-01-29T02:25:45.829Z","comments":true,"path":"2019/05/20/2018-2019-ICPC-NEERC-Southern-Subregional-Contest/","link":"","permalink":"https://yanghaku.github.io/2019/05/20/2018-2019-ICPC-NEERC-Southern-Subregional-Contest/","excerpt":"这套题目难度适中吧，只不过我们队还没做到自己的最好，自闭了好几个小时的题目竟然是水题 题目pdf链接 codeforce提交链接","text":"这套题目难度适中吧，只不过我们队还没做到自己的最好，自闭了好几个小时的题目竟然是水题 题目pdf链接 codeforce提交链接 概览： A. Find a Number B. Berkomnadzor C. Cloud Computing D. Garbage Disposal E. Getting Deals Done F. Debate G. Monsters and Potions H. BerOS File Suggestion I. Privatization of Roads in Berland J. Streets and Avenues in Berhattan K. Video Posts L. Odd Federalization M. Algoland and Berland A. Find a Number 题目大意： 给你一个d(1&lt;=d&lt;=500),和s(1&lt;=s&lt;=5000)，找到一个最小的整数n使得n是d的倍数并且各数位之和为s，不存在就输出-1。 这个题自闭了四个小时还没做出来，其实就是一个简单的bfs！！ 思路：记 dp[x][y] 为余数为x，各数位之和为y的数的最小值，因为数位太大，所以可以用一个string保存。状态转移方程是： dp[(x10+k)%d][y+k]=dp[x][y]+string(k) (0&lt;=k&lt;=9) //其中＋为字符串的连接操作。所以只要找到dp[0][s]即可，初始的状态为dp[k%d][k] (1&lt;=k&lt;=9) (即只有一位的时候） 直接用记忆化的BFS搜索即可，而且这样可以保证每次第一次访问到的状态都是最小的，因为加入队列的顺序是*从小到大的。（有一个与此题非常相似的题，就是因为这个从小到大的特性才能AC—&gt;题目链接：Enigma）。 ac代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;algorithm&gt;#include&lt;string&gt;#include&lt;queue&gt;using namespace std;int d,S;//string str[501][5001];bool vis[501][5001];struct T&#123; int x,y; string s; T(int xx,int yy,string ss):x(xx),y(yy),s(ss)&#123;&#125;&#125;;queue&lt;T&gt;q;int solve()&#123; while(!q.empty())q.pop(); for(int i=1;i&lt;10;++i)&#123; q.emplace(i%d,i,string(1,char(i+'0'))); vis[i%d][i]=1; &#125; while(!q.empty())&#123; int x=q.front().x; int y=q.front().y; string s=q.front().s; q.pop(); if(x==0&amp;&amp;y==S)&#123; cout&lt;&lt;s&lt;&lt;endl; return 0; &#125; for(int i=0;i&lt;10;++i)&#123; if(y+i&gt;S)continue; int id=(x*10+i)%d; if(vis[id][y+i]==0)&#123; vis[id][y+i]=1; q.emplace(id,y+i,s+char(i+'0')); &#125; &#125; &#125; return 1;&#125;int main()&#123; cin&gt;&gt;d&gt;&gt;S; if(solve())cout&lt;&lt;\"-1\"&lt;&lt;endl; return 0;&#125; 优化： 上面的代码跑了1200多ms，虽说没有超时，但是还是完全可以优化的。考虑到每次的状态都需要一个string保存，每次状态转移都是前一个的string复制后再添上一个字符（而其中的复制和动态内存的分配与释放消耗的时间非常多），所以说这个地方可以有很大的优化。考虑到每次状态转移都是只添加一个字符，而其他字符就可以直接用上一个状态的就行，所以可以做成一个链表，每一个状态都保存它上一个状态的地址（两个坐标），就能生成最后的字符串，这样可以节省所有的字符串复制的时间。 代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;algorithm&gt;#include&lt;string&gt;#include&lt;queue&gt;using namespace std;int d,S;//string str[501][5001];bool vis[501][5001];int lastx[501][5001],lasty[501][5001];char ch[501][5001];struct T&#123; int x,y; T(int xx,int yy):x(xx),y(yy)&#123;&#125;&#125;;queue&lt;T&gt;q;void getString(int x,int y)&#123; string s=\"\"; int tmp; while(x!=-1)&#123; s=s+ch[x][y]; tmp=lastx[x][y]; y=lasty[x][y]; x=tmp; &#125; reverse(s.begin(),s.end()); cout&lt;&lt;s&lt;&lt;endl;&#125;int solve()&#123; while(!q.empty())q.pop(); for(int i=1;i&lt;10;++i)&#123; q.emplace(i%d,i); vis[i%d][i]=1; lastx[i%d][i]=-1; lasty[i%d][i]=-1; ch[i%d][i]=i+'0'; &#125; while(!q.empty())&#123; int x=q.front().x; int y=q.front().y; q.pop(); if(x==0&amp;&amp;y==S)&#123; getString(x,y); return 0; &#125; for(int i=0;i&lt;10;++i)&#123; if(y+i&gt;S)continue; int id=(x*10+i)%d; if(vis[id][y+i]==0)&#123; vis[id][y+i]=1; q.emplace(id,y+i); ch[id][y+i]=i+'0'; lastx[id][y+i]=x; lasty[id][y+i]=y; &#125; &#125; &#125; return 1;&#125;int main()&#123; cin&gt;&gt;d&gt;&gt;S; if(solve())cout&lt;&lt;\"-1\"&lt;&lt;endl; return 0;&#125; 两次运行时间对比：(可以发现少了将近1s） B. Berkomnadzor (mid) 字典树大模拟，题目大意：给你n个ip地址(也可能是一个划分的子网）都是使用点分十进制表示法，这n个ip有的属于白名单，有的属于黑名单，然后就是让你把黑名单合并，要求在白名单中的不能属于黑名单，不在白名单中的ip也可以进入黑名单，让你合并后的黑名单个数尽量少。（如果某个ip既在黑名单又在白名单，那么就输出-1。 思路：首先写好点分十进制和二进制ip的相互转化函数，字典树里面只包括0,1字符即可，每个节点要维护当前ip地址(或者子网)是否属于黑名单或者白名单，当前节点之后的子网有没有属于白名单的，有没有属于黑名单的即可。检查冲突：如果下面的所有子网地址都属于一个确定的黑(白)名单，那么就可以判断是否与当前正在插入的ip有冲突，如果到达当前ip的子网掩码长度，就可以判断下面的子网中有没有与此冲突。 注意有子网掩码为0的情况，也就是包括所有的ip的情况。 ac代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;cstring&gt;using namespace std;char buf[30];int ip[100],white;int len,subnet_len,ans,black_num=0;struct node&#123; node* next[2]; bool has_white[2]; bool has_black[2]; bool all_white; bool all_black; node()&#123; memset(next,0,sizeof(next)); memset(has_white,0,sizeof(has_white)); memset(has_black,0,sizeof(has_black)); all_white=all_black=0; &#125; ~node()&#123; if(next[0])delete next[0]; if(next[1])delete next[1]; &#125;&#125;*root;void get_binary()&#123;//将点分十进制变为二进制 if(buf[0]=='+')white=1; else white=0,++black_num; len=strlen(buf); int tot=0; subnet_len=32; for(int i=1;i&lt;len;++i)&#123; int x=0; while(i&lt;len&amp;&amp;buf[i]&gt;='0'&amp;&amp;buf[i]&lt;='9')&#123; x=x*10+buf[i]-'0'; ++i; &#125; if(tot==32)&#123; subnet_len=x; break; &#125; for(int k=0;k&lt;8;++k)&#123; if((x&gt;&gt;(7-k))&amp;1)ip[tot]=1; else ip[tot]=0; ++tot; &#125; &#125;&#125;void change_binary()&#123;//将二进制变为点分十进制 for(int i=0;i&lt;4;++i)&#123; int x=0; for(int j=i*8;j&lt;(i+1)*8&amp;&amp;j&lt;subnet_len;++j)&#123; x=x|(ip[j]&lt;&lt;(7-j+i*8)); &#125; printf(\"%d\",x); if(i==3)&#123; if(subnet_len!=32)printf(\"/%d\\n\",subnet_len); else printf(\"\\n\"); &#125; else printf(\".\"); &#125;&#125;bool insert()&#123; node* p=root; if(subnet_len==0)&#123; if(white)&#123; if(p-&gt;has_black[0]||p-&gt;has_black[1]||p-&gt;all_black)return false; p-&gt;all_white=1; &#125; else&#123; if(p-&gt;has_white[0]||p-&gt;has_white[1]||p-&gt;all_white)return false; p-&gt;all_black=1; &#125; return 1; &#125; for(int i=0;i&lt;32;++i)&#123; if(white)p-&gt;has_white[ip[i]]=1; else p-&gt;has_black[ip[i]]=1; if(!p-&gt;next[ip[i]])p-&gt;next[ip[i]]=new node(); p=p-&gt;next[ip[i]]; if(p-&gt;all_white)&#123; if(white)break; return false;//黑白冲突 &#125; if(p-&gt;all_black)&#123; if(white)return false; break; &#125; if(i==subnet_len-1)&#123; if(white)&#123; p-&gt;all_white=1; if(p-&gt;has_black[0]||p-&gt;has_black[1])return false; &#125; else&#123; p-&gt;all_black=1; if(p-&gt;has_white[0]||p-&gt;has_white[1])return false; &#125; break; &#125; &#125; return 1;&#125;void dfs_num(node* now,int num)&#123; if(now-&gt;all_white)return; if(now-&gt;all_black|| (!now-&gt;has_white[0]&amp;&amp;!now-&gt;has_white[1]))&#123; ++ans; return; &#125; if(now-&gt;next[0])&#123; ip[num]=0; dfs_num(now-&gt;next[0],num+1); &#125; if(now-&gt;next[1])&#123; ip[num]=1; dfs_num(now-&gt;next[1],num+1); &#125;&#125;void dfs(node* now,int num)&#123; if(now-&gt;all_white)return; if(now-&gt;all_black || (!now-&gt;has_white[0]&amp;&amp;!now-&gt;has_white[1]))&#123; subnet_len=num; change_binary(); return; &#125; if(now-&gt;next[0])&#123; ip[num]=0; dfs(now-&gt;next[0],num+1); &#125; if(now-&gt;next[1])&#123; ip[num]=1; dfs(now-&gt;next[1],num+1); &#125;&#125;int main()&#123; root=new node(); int n;cin&gt;&gt;n; while(n--)&#123; scanf(\"%s\",buf); get_binary(); if(!insert())&#123; cout&lt;&lt;\"-1\"&lt;&lt;endl; return 0; &#125; &#125; if(black_num==0)&#123; cout&lt;&lt;\"-1\"&lt;&lt;endl; return 0; &#125; ans=0; dfs_num(root,0); cout&lt;&lt;ans&lt;&lt;endl; dfs(root,0); delete root; return 0;&#125; C. Cloud Computing pending --- D. Garbage Disposal 签到题一枚，题目大意是给你n天的每天的垃圾量，每个垃圾只能在当天或者第二天扔掉（不能放到第三天），垃圾只能装到包里才能扔，所以给你一个k，表示每个包最多能盛放多少垃圾。问最小需要多少个包。思路：直接贪心即可，每天把当天需要扔的垃圾整除k（装包扔掉），余数（即剩下不够装满一个包）就放到第二天扔。但是要注意垃圾不能存到第三天，所以只要保证当天扔的垃圾大于前一天剩下的即可。ac代码：12345678910111213141516171819202122#include&lt;iostream&gt;using namespace std;int main()&#123; long long n,k,last=0,a,ans=0,tmp; cin&gt;&gt;n&gt;&gt;k; while(n--)&#123; cin&gt;&gt;a; a+=last; tmp=a/k; a%=k; if(tmp*k&lt;last)&#123; //如果当天扔的小于昨天剩下的，也要强制扔去 ++tmp; a=0; &#125; ans+=tmp; last=a; &#125; if(last)++ans;//如果最后还剩下，就直接装包扔掉 cout&lt;&lt;ans&lt;&lt;endl; return 0;&#125; E. Getting Deals Done pending --- F. Debate 题目大意：给你n（1","categories":[{"name":"平时训练の补题","slug":"平时训练の补题","permalink":"https://yanghaku.github.io/categories/%E5%B9%B3%E6%97%B6%E8%AE%AD%E7%BB%83%E3%81%AE%E8%A1%A5%E9%A2%98/"}],"tags":[{"name":"codeforces","slug":"codeforces","permalink":"https://yanghaku.github.io/tags/codeforces/"}],"author":"yb"},{"title":"my first blog","slug":"my-first-blog","date":"2019-05-20T00:30:00.000Z","updated":"2019-05-20T00:52:33.000Z","comments":true,"path":"2019/05/20/my-first-blog/","link":"","permalink":"https://yanghaku.github.io/2019/05/20/my-first-blog/","excerpt":"从现在开始，2019.5.20，我将拥有自己的博客了。 对我来说写博客的用处有一下几点：","text":"从现在开始，2019.5.20，我将拥有自己的博客了。 对我来说写博客的用处有一下几点： 每天总结自己做过的题目，加深思考。 为自己写过的代码做备份，之前一直保存在本地，虽然都用文件夹做了分类，但是还是查找不方便，而且有时又懒得保存。 克服自己的懒惰，到了现在，看了自己的github，自己已经有半年没有好好写代码了，不仅仅是手懒，脑子也变得懒了，记得前几天教练还说过：我们已经停止了思考。对，就是停止了思考！现在的程度，是对许多的算法都知道，但是却不能静下心来仔细研究其中的原理和更深层的应用。没有了思考，也就没有了提高，只靠板子是做不了题的！ 所以从此，加油，克服自己的懒惰，才能提高！ 博客名字以后再想吧……","categories":[],"tags":[],"author":"yb"}]}